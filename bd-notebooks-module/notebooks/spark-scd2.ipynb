{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bac3cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/21 19:21:50 WARN Utils: Your hostname, vmware-ubuntu-24.04 resolves to a loopback address: 127.0.1.1; using 192.168.154.133 instead (on interface ens33)\n",
      "25/10/21 19:21:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/21 19:21:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.window import Window\n",
    "from os import path, listdir\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"spark-scd2-implementation\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a1b55",
   "metadata": {},
   "source": [
    "#### Daimention Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6561cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-------+------+--------------------+------------------+\n",
      "|id |name  |city   |country|active|effective_start_date|effective_end_date|\n",
      "+---+------+-------+-------+------+--------------------+------------------+\n",
      "|1  |manish|arwal  |india  |N     |2022-09-15          |2022-09-25        |\n",
      "|2  |vikash|patna  |india  |Y     |2023-08-12          |NULL              |\n",
      "|3  |nikita|delhi  |india  |Y     |2023-09-10          |NULL              |\n",
      "|4  |rakesh|jaipur |india  |Y     |2023-06-10          |NULL              |\n",
      "|5  |ayush |NY     |USA    |Y     |2023-06-10          |NULL              |\n",
      "|1  |manish|gurgaon|india  |Y     |2022-09-25          |NULL              |\n",
      "+---+------+-------+-------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_dim_data = [\n",
    "\n",
    "(1,'manish','arwal','india','N','2022-09-15','2022-09-25'),\n",
    "(2,'vikash','patna','india','Y','2023-08-12',None),\n",
    "(3,'nikita','delhi','india','Y','2023-09-10',None),\n",
    "(4,'rakesh','jaipur','india','Y','2023-06-10',None),\n",
    "(5,'ayush','NY','USA','Y','2023-06-10',None),\n",
    "(1,'manish','gurgaon','india','Y','2022-09-25',None),\n",
    "]\n",
    "\n",
    "customer_schema= ['id','name','city','country','active','effective_start_date','effective_end_date']\n",
    "\n",
    "customer_dim_df = spark.createDataFrame(data= customer_dim_data,schema=customer_schema)\n",
    "customer_dim_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18227fc0",
   "metadata": {},
   "source": [
    "#### Fact Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b12194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n",
      "|sales_id|customer_id|customer_name|sales_date|food_delivery_address|food_delivery_country|food_cost|\n",
      "+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n",
      "|1       |1          |manish       |2023-01-16|gurgaon              |india                |380      |\n",
      "|77      |1          |manish       |2023-03-11|bangalore            |india                |300      |\n",
      "|12      |3          |nikita       |2023-09-20|delhi                |india                |127      |\n",
      "|54      |4          |rakesh       |2023-08-10|jaipur               |india                |321      |\n",
      "|65      |5          |ayush        |2023-09-07|mosco                |russia               |765      |\n",
      "|89      |6          |rajat        |2023-08-10|jaipur               |india                |321      |\n",
      "+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_data = [\n",
    "\n",
    "(1,1,'manish','2023-01-16','gurgaon','india',380),\n",
    "(77,1,'manish','2023-03-11','bangalore','india',300),\n",
    "(12,3,'nikita','2023-09-20','delhi','india',127),\n",
    "(54,4,'rakesh','2023-08-10','jaipur','india',321),\n",
    "(65,5,'ayush','2023-09-07','mosco','russia',765),\n",
    "(89,6,'rajat','2023-08-10','jaipur','india',321)\n",
    "]\n",
    "\n",
    "sales_schema = ['sales_id', 'customer_id','customer_name', 'sales_date', 'food_delivery_address','food_delivery_country', 'food_cost']\n",
    "\n",
    "sales_df = spark.createDataFrame(data=sales_data,schema=sales_schema)\n",
    "sales_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61fe7d7",
   "metadata": {},
   "source": [
    "#### Join Dataframes to identify change in address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d60990f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-------+------+--------------------+------------------+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n",
      "|id |name  |city   |country|active|effective_start_date|effective_end_date|sales_id|customer_id|customer_name|sales_date|food_delivery_address|food_delivery_country|food_cost|\n",
      "+---+------+-------+-------+------+--------------------+------------------+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n",
      "|1  |manish|arwal  |india  |N     |2022-09-15          |2022-09-25        |77      |1          |manish       |2023-03-11|bangalore            |india                |300      |\n",
      "|1  |manish|arwal  |india  |N     |2022-09-15          |2022-09-25        |1       |1          |manish       |2023-01-16|gurgaon              |india                |380      |\n",
      "|2  |vikash|patna  |india  |Y     |2023-08-12          |NULL              |NULL    |NULL       |NULL         |NULL      |NULL                 |NULL                 |NULL     |\n",
      "|3  |nikita|delhi  |india  |Y     |2023-09-10          |NULL              |12      |3          |nikita       |2023-09-20|delhi                |india                |127      |\n",
      "|4  |rakesh|jaipur |india  |Y     |2023-06-10          |NULL              |54      |4          |rakesh       |2023-08-10|jaipur               |india                |321      |\n",
      "|5  |ayush |NY     |USA    |Y     |2023-06-10          |NULL              |65      |5          |ayush        |2023-09-07|mosco                |russia               |765      |\n",
      "|1  |manish|gurgaon|india  |Y     |2022-09-25          |NULL              |77      |1          |manish       |2023-03-11|bangalore            |india                |300      |\n",
      "|1  |manish|gurgaon|india  |Y     |2022-09-25          |NULL              |1       |1          |manish       |2023-01-16|gurgaon              |india                |380      |\n",
      "+---+------+-------+-------+------+--------------------+------------------+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_data = customer_dim_df.join(sales_df, (customer_dim_df.id == sales_df.customer_id), how='left')\n",
    "joined_data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734b515",
   "metadata": {},
   "source": [
    "#### Identify records with changes in address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d0e19f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---------+---------------------+------+--------------------+------------------+\n",
      "|id |customer_name|city     |food_delivery_country|active|effective_start_date|effective_end_date|\n",
      "+---+-------------+---------+---------------------+------+--------------------+------------------+\n",
      "|1  |manish       |bangalore|india                |Y     |2023-03-11          |NULL              |\n",
      "|5  |ayush        |mosco    |russia               |Y     |2023-09-07          |NULL              |\n",
      "+---+-------------+---------+---------------------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_records_df = joined_data.where((col(\"food_delivery_address\") != col(\"city\")) & (col(\"active\") == 'Y'))\\\n",
    "                    .withColumn(\"active\", lit(\"Y\"))\\\n",
    "                    .withColumn(\"effective_start_date\", col(\"sales_date\"))\\\n",
    "                    .withColumn(\"effective_end_date\", lit(None))\\\n",
    "                    .select(\n",
    "                        \"id\",\n",
    "                        \"customer_name\",\n",
    "                        col(\"food_delivery_address\").alias(\"city\"),\n",
    "                        \"food_delivery_country\",\n",
    "                        \"active\",\n",
    "                        \"effective_start_date\",\n",
    "                        \"effective_end_date\"\n",
    "                    )\n",
    "\n",
    "new_records_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c893a8",
   "metadata": {},
   "source": [
    "#### Update the old Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e029676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-------+---------------------+------+--------------------+------------------+\n",
      "|id |customer_name|city   |food_delivery_country|active|effective_start_date|effective_end_date|\n",
      "+---+-------------+-------+---------------------+------+--------------------+------------------+\n",
      "|1  |manish       |gurgaon|india                |N     |2022-09-25          |2023-03-11        |\n",
      "|5  |ayush        |NY     |russia               |N     |2023-06-10          |2023-09-07        |\n",
      "+---+-------------+-------+---------------------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "old_records_df = joined_data.where((col(\"food_delivery_address\") != col(\"city\")) & (col(\"active\") == 'Y'))\\\n",
    "                    .withColumn(\"active\", lit(\"N\"))\\\n",
    "                    .withColumn(\"effective_end_date\", col(\"sales_date\"))\\\n",
    "                    .select(\n",
    "                        \"id\",\n",
    "                        \"customer_name\",\n",
    "                        \"city\",\n",
    "                        \"food_delivery_country\",\n",
    "                        \"active\",\n",
    "                        \"effective_start_date\",\n",
    "                        \"effective_end_date\"\n",
    "                    )\n",
    "\n",
    "old_records_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5922ee8d",
   "metadata": {},
   "source": [
    "#### Findout new Records & Insert Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "400a9804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------------------+---------------------+------+--------------------+------------------+\n",
      "|customer_id|customer_name|food_delivery_address|food_delivery_country|active|effective_start_date|effective_end_date|\n",
      "+-----------+-------------+---------------------+---------------------+------+--------------------+------------------+\n",
      "|6          |rajat        |jaipur               |india                |Y     |2023-08-10          |NULL              |\n",
      "+-----------+-------------+---------------------+---------------------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_customer_df = sales_df.join(customer_dim_df, \n",
    "                                (sales_df.customer_id == customer_dim_df.id), \n",
    "                                how='leftanti')\\\n",
    "                    .withColumn(\"active\", lit(\"Y\"))\\\n",
    "                    .withColumn(\"effective_start_date\", col(\"sales_date\"))\\\n",
    "                    .withColumn(\"effective_end_date\", lit(None))\\\n",
    "                    .select(\n",
    "                        \"customer_id\",\n",
    "                        \"customer_name\",\n",
    "                        \"food_delivery_address\",\n",
    "                        \"food_delivery_country\",\n",
    "                        \"active\",\n",
    "                        \"effective_start_date\",\n",
    "                        \"effective_end_date\"\n",
    "                    )\n",
    "new_customer_df.show(truncate=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbddab57",
   "metadata": {},
   "source": [
    "#### Merge all records into one DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2c528a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+-------+------+--------------------+------------------+\n",
      "|id |name  |city     |country|active|effective_start_date|effective_end_date|\n",
      "+---+------+---------+-------+------+--------------------+------------------+\n",
      "|1  |manish|arwal    |india  |N     |2022-09-15          |2022-09-25        |\n",
      "|2  |vikash|patna    |india  |Y     |2023-08-12          |NULL              |\n",
      "|3  |nikita|delhi    |india  |Y     |2023-09-10          |NULL              |\n",
      "|4  |rakesh|jaipur   |india  |Y     |2023-06-10          |NULL              |\n",
      "|5  |ayush |NY       |USA    |Y     |2023-06-10          |NULL              |\n",
      "|1  |manish|gurgaon  |india  |Y     |2022-09-25          |NULL              |\n",
      "|1  |manish|bangalore|india  |Y     |2023-03-11          |NULL              |\n",
      "|5  |ayush |mosco    |russia |Y     |2023-09-07          |NULL              |\n",
      "|1  |manish|gurgaon  |india  |N     |2022-09-25          |2023-03-11        |\n",
      "|5  |ayush |NY       |russia |N     |2023-06-10          |2023-09-07        |\n",
      "|6  |rajat |jaipur   |india  |Y     |2023-08-10          |NULL              |\n",
      "+---+------+---------+-------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_records = customer_dim_df.union(new_records_df).union(old_records_df).union(new_customer_df)\n",
    "final_records.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e4e2bc",
   "metadata": {},
   "source": [
    "#### Remove Duplicate Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea890a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+-------+------+--------------------+------------------+\n",
      "|id |name  |city     |country|active|effective_start_date|effective_end_date|\n",
      "+---+------+---------+-------+------+--------------------+------------------+\n",
      "|1  |manish|gurgaon  |india  |N     |2022-09-25          |2023-03-11        |\n",
      "|1  |manish|arwal    |india  |N     |2022-09-15          |2022-09-25        |\n",
      "|1  |manish|bangalore|india  |Y     |2023-03-11          |NULL              |\n",
      "|2  |vikash|patna    |india  |Y     |2023-08-12          |NULL              |\n",
      "|3  |nikita|delhi    |india  |Y     |2023-09-10          |NULL              |\n",
      "|4  |rakesh|jaipur   |india  |Y     |2023-06-10          |NULL              |\n",
      "|5  |ayush |NY       |russia |N     |2023-06-10          |2023-09-07        |\n",
      "|5  |ayush |mosco    |russia |Y     |2023-09-07          |NULL              |\n",
      "|6  |rajat |jaipur   |india  |Y     |2023-08-10          |NULL              |\n",
      "+---+------+---------+-------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy(\"id\",\"active\").orderBy(col(\"effective_start_date\").desc())\n",
    "\n",
    "deduped_final_records = final_records.withColumn(\"rnk\", rank().over(window))\\\n",
    "                    .filter(~((col(\"rnk\") >= 2) & (col(\"active\") == \"Y\")))\\\n",
    "                    .drop(\"rnk\")\n",
    "\n",
    "deduped_final_records.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1828f4bb",
   "metadata": {},
   "source": [
    "Final data need to replace in system. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_python3_11_13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
