<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="AutoImportSettings">
    <option name="autoReloadType" value="SELECTIVE" />
  </component>
  <component name="ChangeListManager">
    <list default="true" id="3bdc845a-73b0-4b8f-9160-c36ec6b5b17f" name="Changes" comment="2024-09-14 Update Project Configuration.">
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/bd-notebooks-module.iml" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/.ipynb_checkpoints/hello-noteboot-checkpoint.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/hello-noteboot.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/iceberg/.ipynb_checkpoints/Iceberg - Getting Started-checkpoint.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/iceberg/.ipynb_checkpoints/MinIOTest-checkpoint.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/iceberg/.ipynb_checkpoints/iceberg-jdbc-checkpoint.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/iceberg/.ipynb_checkpoints/spark-java-checkpoint.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/iceberg/.ipynb_checkpoints/spark-python-checkpoint.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/iceberg/.ipynb_checkpoints/spark-scala-checkpoint.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/iceberg/Iceberg - Getting Started.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/iceberg/MinIOTest.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/iceberg/iceberg-jdbc.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/iceberg/spark-java.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/iceberg/spark-python.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks/iceberg/spark-scala.ipynb" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Flink Tutorial/1. Flink Basics_2F2YS7PCE.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Flink Tutorial/2. Three Essential Steps for Building Flink Job_2F7SKEHPA.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Flink Tutorial/3. Flink Job Control Tutorial_2F5RKHCDV.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Flink Tutorial/4. Streaming ETL_2EYD56B9B.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Flink Tutorial/5. Streaming Data Analytics_2EYT7Q6R8.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Flink Tutorial/6. Batch ETL_2EW19CSPA.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Flink Tutorial/7. Batch Data Analytics_2EZ9G3JJU.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Flink Tutorial/8. Logistic Regression (Alink)_2F4HJNWVN.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hadoop/hadoop-commands_2HKVQKV3U.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hadoop/hdfs-commands_2HNX4CQUP.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hadoop/test-file_2GRN2Y6FJ.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hbase/hbase-test_2GRB7W8PH.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hbase/hortonworks-shc-connector_2GSAZR9BQ.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hbase/spark-hbase-connector_2GRH9CDWB.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-bucket-map-join_2GU6EBT4X.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-bucketed-tables_2GR8HW4Z6.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-datatypes_2GSNF1KSC.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-dstream-table_2GTVB8B4U.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-eliminate-duplicates_2GU88EVG7.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-hbase-external-tables_2GSP2W6RS.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-joins-types_2GQEU54D9.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-lateral-view_2GTVFKP3X.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-map-join_2GVGXFWN1.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-partition-tables_2GSAUWYDK.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-practice_2GS8BEJJX.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-sortmerge-bucket-map-join_2GWFKWKD4.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-split-column_2HK26F2JD.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-table-orc_2HKKT2KVK.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-table-parquet_2HJ48CVNN.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-transaction-data-pipeline_2GS1ZX4SG.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive-window-functions_2HHQWQ4CE.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Hive/hive_flight_data_2JSY2DGQ2.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Iceberg/iceberg_tables_2JSPJME8F.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Miscellaneous Tutorial/Using Mahout_2BYEZ5EVK.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Miscellaneous Tutorial/Using Pig for querying data_2C57UKYWR.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Monitoring/spark-cluster-graphite-metrics_2HQV3V6XH.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Monitoring/spark-cluster-jmx-metrics_2HSNE1B6C.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Monitoring/spark-cluster-prometheus-metrics_2HSWTDXY7.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Monitoring/spark-cluster-statsd-metrics_2HR615J5B.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Mysql/mysql-test_2HM338ASK.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/Car_Loan_Data_Analysis_2GUX3Z4HM.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/Card_Transaction_Analysis_2GT4KUKKG.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/Transforming Complex Data Types in Spark SQL_2GUCGJQUE.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/azure_2HM62FCUG.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/joins/bucketed-sort-merge-join_2GQ2QU2U9.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/joins/sort_merge_join_2HPC5QCXZ.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/logical_physical_plans_2GSB9H2KW.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-data-frames_2GP9RXBET.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-delta-table_2HK4A8YWE.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-df-distinct_2GR1FZHBM.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-df-groupby_2GSH6FF7F.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-hash-partitioner_2GQ7X5UAN.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-hive-hbase_2GRHRBP3V.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-hive-tables_2HF6UJS5M.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-large-tables_2GR1BU96F.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-matplotlib_2HN1XXMZT.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-secondary-sort(car-data)_2GTMZQEGC.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-secondary-sort(in-reducer)_2HM1623AT.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-secondary-sort(in-shuffle)_2HMEHDPT5.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-sort-merge-join_2GRDH7B9W.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark-table-types_2HMAW1Q7V.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/pyspark_zero_value_in_aggregatebykey_2H8FH47UV.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/rdd/pyspark-local-rdd-actions_2GSCYK9TW.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/rdd/pyspark-paired-rdd-transformations_2GSKPE7D5.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/rdd/pyspark-rdd-mapvalue_2HJ4FXFUV.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/rdd/rdd-actions_2HK5PXGEK.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/spark_session_catalog_2HMCG3GW8.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/stream/kafka_structured_batch_2HKUFJTM6.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/stream/kafka_structured_stream_2GS3G93GM.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/PySpark/stream/rate_structured_stream_2HK8JVHW2.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Python 3 (ipykernel)_2HN1YYPCS.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Python 3_2GSNWVBEW.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Python Tutorial/1. IPython Basic_2EYDJKFFY.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Python Tutorial/2. IPython Visualization Tutorial_2F1S9ZY8Z.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Python Tutorial/3. Keras Binary Classification (IMDB)_2F2AVWJ77.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Python Tutorial/4. Matplotlib (Python, PySpark)_2C2AUG798.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Python/hash-lib-example_2H4YP6GKM.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Python/python-dates_2HNSUM9KF.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Python/python-test_2GRJMVUFZ.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/R Tutorial/1. R Basics_2BWJFTXKJ.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/R Tutorial/2. Shiny App_2EZ66TM57.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/R Tutorial/3. R Conda Env in Yarn Mode_2GB9HRSH9.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/README.md" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/SPARK Certification Guide/Chap 01 to 05 -SPARK and AzureDB basics_2GTBCSAFZ.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/SPARK Certification Guide/Chap 06 - Working with Different Types of Data_2HCXQNXQD.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/SPARK Certification Guide/Chap 07 - Aggregations_2HFNBRUEQ.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/SPARK Certification Guide/Chap 08- Joins_2HD81RW9D.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/SPARK Certification Guide/Chap 09 - Data Sources_2HDVVPS9E.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/SPARK Certification Guide/Chap 10- Spark SQL_2HF4RY2P4.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark Streaming_2HK44BKKJ.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark Tutorial/1. Spark Interpreter Introduction_2F8KN6TKK.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark Tutorial/2. Spark Basic Features_2A94M5J1Z.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark Tutorial/3. Spark SQL (PySpark)_2EWM84JXA.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark Tutorial/3. Spark SQL (Scala)_2EYUV26VR.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark Tutorial/4. Spark MlLib_2EZFM3GJA.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark Tutorial/5. SparkR Basics_2BWJFTXKM.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark Tutorial/6. SparkR Shiny App_2F1CHQ4TT.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark Tutorial/7. Spark Delta Lake Tutorial_2F8VDBMMT.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark Tutorial/8. PySpark Conda Env in Yarn Mode_2GE79Y5FV.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/ByKeyOperations_2GRM1Q447.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/CombineByKeyOperation_2GT17UUHP.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/DataFormats/spark_orc_example_2GS9Z7YNU.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/DataFormats/spark_parquet_example_2GTV67G8V.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/Datasources/avro-data-frames_2GRU1SC85.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/Datasources/pyspark-parquet_2GT7FHX41.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/Partitioners/Hash-Partitioner_2GR9WHD4V.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/Seacondary_Sort_Example_2GV5E219U.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/Stream/kafka-streaming-example_2HKZHZPA8.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/WindowsFunctions_2H29Q41HK.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/accumulators_2HNRGMPME.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/broadcast-hash-join_2GRZN5DS9.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/broadcast_nestedloop_join_2GQDFN3RM.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/cache_and_persist_2GSQSK2QB.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/cartesian-join_2GS9X2UCC.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/cost_based_optimization_2GT743VVU.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/elastic-search_2GQNA92JB.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/randam-dataframes_2GTE5PYAP.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/shuffel-sort-merge-join_2GRFYSSBQ.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/shuffle-hash-join_2GRFYA2BN.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/spark-join-hints_2GS65GYQ5.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/Spark/string-functions_2GTM6Q93U.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/cassandra/spark-connection_2HSMCN7HV.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/cassandra/test-cassandra_2GRXY2AC7.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/elasticsearch/test-elastic-search_2GR3TPK3J.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/images/hadoop-hdfs.png" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/spark-local_2GQKZNMZB.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/spark-yarn-client_2GN1VCU82.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/spark-yarn-cluster_2GP4KFVM4.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks/test-shell_2GTZDXJT9.zpln" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-spark-module/src/main/java/org/examples/spark/SparkAppWorkflow.java" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-spark-module/src/test/resources/core-site.xml" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/bd-spark-module/src/test/resources/hive-site.xml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/.idea/misc.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/misc.xml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/.idea/modules.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/modules.xml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/bd-docker-sandbox/docker-compose.yaml" beforeDir="false" afterPath="$PROJECT_DIR$/bd-docker-sandbox/docker-compose.yaml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/bd-hadoop-sandbox/dc-spark-cluster.yml" beforeDir="false" afterPath="$PROJECT_DIR$/bd-hadoop-sandbox/dc-spark-cluster.yml" afterDir="false" />
    </list>
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="FileTemplateManagerImpl">
    <option name="RECENT_TEMPLATES">
      <list>
        <option value="Python Script" />
        <option value="Class" />
      </list>
    </option>
  </component>
  <component name="Git.Settings">
    <option name="RECENT_BRANCH_BY_REPOSITORY">
      <map>
        <entry key="$PROJECT_DIR$" value="main" />
      </map>
    </option>
    <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
  </component>
  <component name="GitHubPullRequestSearchHistory">{
  &quot;lastFilter&quot;: {
    &quot;state&quot;: &quot;OPEN&quot;,
    &quot;assignee&quot;: &quot;brijeshdhaker&quot;
  }
}</component>
  <component name="GithubPullRequestsUISettings">{
  &quot;selectedUrlAndAccountId&quot;: {
    &quot;url&quot;: &quot;https://github.com/brijeshdhaker/docker-hadoop-cluster.git&quot;,
    &quot;accountId&quot;: &quot;95107e20-1155-4435-9405-1e037b209791&quot;
  }
}</component>
  <component name="MarkdownSettingsMigration">
    <option name="stateVersion" value="1" />
  </component>
  <component name="MavenImportPreferences">
    <option name="generalSettings">
      <MavenGeneralSettings>
        <option name="useMavenConfig" value="false" />
      </MavenGeneralSettings>
    </option>
  </component>
  <component name="ProblemsViewState">
    <option name="selectedTabId" value="CurrentFile" />
  </component>
  <component name="ProjectCodeStyleSettingsMigration">
    <option name="version" value="2" />
  </component>
  <component name="ProjectColorInfo">{
  &quot;associatedIndex&quot;: 4
}</component>
  <component name="ProjectId" id="2cX3TktHfGdHsUFzByi07LxLGH3" />
  <component name="ProjectLevelVcsManager" settingsEditedManually="true" />
  <component name="ProjectViewState">
    <option name="hideEmptyMiddlePackages" value="true" />
    <option name="showLibraryContents" value="true" />
  </component>
  <component name="PropertiesComponent"><![CDATA[{
  "keyToString": {
    "Application.SparkAppWorkflow.executor": "Run",
    "Application.SparkPi.executor": "Run",
    "Docker.Docker Image.executor": "Run",
    "Docker.bd-docker-sandbox/dc-hadoop-cluster.yaml.datanode: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-hadoop-cluster.yaml.namenode: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-hadoop-cluster.yaml: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-hive-cluster.yaml.hiveserver: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-hive-cluster.yaml.metastore: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-hive-cluster.yaml: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-kafka-cluster.yaml.kafkabroker: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-kafka-cluster.yaml.schemaregistry: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-kafka-cluster.yaml.zookeeper: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-kafka-cluster.yaml: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-mysqlserver.yaml.mysqlserver: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-spark-cluster.yml.spark-master: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-spark-cluster.yml.spark-worker-a: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-spark-cluster.yml.spark-worker-b: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-spark-cluster.yml.sparkhistory: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/dc-spark-cluster.yml: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/docker-compose.yaml.gateway: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/docker-compose.yaml.hiveserver: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/docker-compose.yaml.metastore: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/docker-compose.yaml.mysqlserver: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/docker-compose.yaml.zeppelin: Compose Deployment.executor": "Run",
    "Docker.bd-docker-sandbox/docker-compose.yaml: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox.gateway: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox.zeppelin: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-hadoop-cluster.yaml: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-hive-cluster.yml.hiveserver: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-iceburg.yml.iceberg-rest: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-iceburg.yml.mc: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-iceburg.yml.rest: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-iceburg.yml.spark-iceberg: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-iceburg.yml: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-kafka.yml.kafkabroker: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-kafka.yml.kdcserver: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-kafka.yml.zookeeper: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-kafka.yml: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-kdcserver.yml.kdcserver: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-minio.yml.mc: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-minio.yml.minio: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-spark-cluster.yml.spark-notebook: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox/dc-spark-cluster.yml.sparkhistory: Compose Deployment.executor": "Run",
    "Docker.bd-hadoop-sandbox: Compose Deployment.executor": "Run",
    "Docker.dc-iceburg.yml.mc: Compose Deployment.executor": "Run",
    "Docker.dc-iceburg.yml.minio: Compose Deployment.executor": "Run",
    "Docker.dc-iceburg.yml.rest: Compose Deployment.executor": "Run",
    "Docker.dc-iceburg.yml.spark-iceberg: Compose Deployment.executor": "Run",
    "Docker.dc-kafka.yml.kafkabroker: Compose Deployment.executor": "Run",
    "Docker.dc-kafka.yml.kafkaclient: Compose Deployment.executor": "Run",
    "Docker.dc-kafka.yml.kdcserver: Compose Deployment.executor": "Run",
    "Docker.dc-kafka.yml.zookeeper: Compose Deployment.executor": "Run",
    "Docker.dc-kafka.yml: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.datanode: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.gateway: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.historyserver: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.hiveserver: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.hivetezui: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.hmaster: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.hregion: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.kdcserver: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.metastore: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.mysqlserver: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.namenode: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.nodemanager: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.resourcemanager: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.sparkhistory: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml.timelineserver: Compose Deployment.executor": "Run",
    "Docker.docker-compose.yml: Compose Deployment.executor": "Run",
    "Docker.ubuntu.executor": "Run",
    "Maven.bd-python-module [clean].executor": "Run",
    "Maven.bd-python-module [install].executor": "Run",
    "Maven.bd-python-module [org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy].executor": "Run",
    "Maven.bd-python-module [package].executor": "Run",
    "Maven.bd-python-module [verify].executor": "Run",
    "Maven.bd-spark-module [package].executor": "Run",
    "Python tests.Python tests for test_Commons.test_print_separator.executor": "Run",
    "Python tests.Python tests for test_Commons.test_split_csv.executor": "Run",
    "Python tests.Python tests for test_Commons.test_split_csv_line.executor": "Debug",
    "Python tests.Python tests for test_User.test_random.executor": "Debug",
    "Python tests.Python tests for test_User.test_to_dict.executor": "Debug",
    "Python tests.Python tests for test_User.test_to_obj.executor": "Run",
    "Python tests.Python tests for test_static.test_flake8.executor": "Debug",
    "Python tests.Python tests in test_Commons.py.executor": "Debug",
    "Python tests.Python tests in test_User.py.executor": "Run",
    "Python.FileUtils.executor": "Run",
    "Python.Order.executor": "Run",
    "Python.TimeUtils.executor": "Run",
    "Python.User.executor": "Run",
    "Python.app.executor": "Run",
    "Python.avro-test.executor": "Debug",
    "Python.confluent_kafka_AvroConsumer.executor": "Run",
    "Python.confluent_kafka_AvroProducer.executor": "Run",
    "Python.confluent_kafka_ConsumerFactory.executor": "Run",
    "Python.confluent_kafka_DeserializingConsumer.executor": "Debug",
    "Python.confluent_kafka_ProducerFactory.executor": "Run",
    "Python.confluent_kafka_SerializingProducer.executor": "Run",
    "Python.confluent_kafka_simple_consumer.executor": "Run",
    "Python.confluent_transaction_producer.executor": "Run",
    "Python.hello-spark.executor": "Run",
    "Python.kafka_python_partitioned_consumer.executor": "Run",
    "Python.kafka_python_partitioned_producer.executor": "Run",
    "Python.kafka_python_simple_consumer.executor": "Run",
    "Python.kafka_python_simple_producer.executor": "Run",
    "Python.main.executor": "Run",
    "Python.pie.executor": "Run",
    "Python.pyspark-pandas.executor": "Run",
    "Python.run_tests.executor": "Run",
    "Python.sql-s3a-read.executor": "Run",
    "Python.structured-avro-stream.executor": "Debug",
    "Python.test.executor": "Run",
    "RunOnceActivity.OpenProjectViewOnStart": "true",
    "RunOnceActivity.ShowReadmeOnStart": "true",
    "SHARE_PROJECT_CONFIGURATION_FILES": "true",
    "git-widget-placeholder": "develop/docker-hadoop334-cluster",
    "jdk.selected.JAVA_MODULE": "1.8",
    "kotlin-language-version-configured": "true",
    "last_opened_file_path": "/home/brijeshdhaker/IdeaProjects/docker-hadoop-cluster/bd-notebooks-module",
    "onboarding.tips.debug.path": "/home/brijeshdhaker/IdeaProjects/docker-hadoop-cluster/docker-java-module/src/main/java/org/examples/hadoop/Main.java",
    "project.structure.last.edited": "SDKs",
    "project.structure.proportion": "0.15",
    "project.structure.side.proportion": "0.31724137",
    "run.code.analysis.last.selected.profile": "pProject Default",
    "settings.editor.selected.configurable": "reference.settings.project.maven.archetype.catalogs"
  }
}]]></component>
  <component name="RecentsManager">
    <key name="CopyFile.RECENT_KEYS">
      <recent name="$PROJECT_DIR$/bd-notebooks-module" />
      <recent name="$PROJECT_DIR$/bd-spark-module/src/test/resources" />
      <recent name="$PROJECT_DIR$/bd-spark-module/src/main/resources" />
      <recent name="$PROJECT_DIR$/bd-docker-sandbox/conf/hadoop/client" />
      <recent name="$PROJECT_DIR$/bd-docker-sandbox/conf/hadoop/conf" />
    </key>
    <key name="MoveFile.RECENT_KEYS">
      <recent name="$PROJECT_DIR$/bd-notebooks-module/jupyter/notebooks" />
      <recent name="$PROJECT_DIR$/bd-notebooks-module/zeppelin/notebooks" />
      <recent name="$PROJECT_DIR$/bd-notebooks-module/zeppelin" />
      <recent name="$PROJECT_DIR$/readme-resources/images" />
      <recent name="$PROJECT_DIR$/readme-resources" />
    </key>
  </component>
  <component name="RunManager" selected="Docker.bd-hadoop-sandbox/dc-spark-cluster.yml.spark-notebook: Compose Deployment">
    <configuration name="SparkAppWorkflow" type="Application" factoryName="Application" temporary="true" nameIsGenerated="true">
      <option name="MAIN_CLASS_NAME" value="org.examples.spark.SparkAppWorkflow" />
      <module name="bd-spark-module" />
      <extension name="coverage">
        <pattern>
          <option name="PATTERN" value="org.examples.spark.*" />
          <option name="ENABLED" value="true" />
        </pattern>
      </extension>
      <method v="2">
        <option name="Make" enabled="true" />
      </method>
    </configuration>
    <configuration name="SparkPi" type="Application" factoryName="Application" temporary="true">
      <option name="MAIN_CLASS_NAME" value="org.examples.spark.SparkPi" />
      <module name="bd-spark-module" />
      <extension name="coverage">
        <pattern>
          <option name="PATTERN" value="org.examples.spark.*" />
          <option name="ENABLED" value="true" />
        </pattern>
      </extension>
      <method v="2">
        <option name="Make" enabled="true" />
      </method>
    </configuration>
    <configuration default="true" type="JetRunConfigurationType">
      <method v="2">
        <option name="Make" enabled="true" />
      </method>
    </configuration>
    <configuration default="true" type="KotlinStandaloneScriptRunConfigurationType">
      <option name="filePath" />
      <method v="2">
        <option name="Make" enabled="true" />
      </method>
    </configuration>
    <configuration default="true" type="PythonConfigurationType" factoryName="Python">
      <option name="ENV_FILES" value="" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <module name="" />
      <option name="SCRIPT_NAME" value="" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration default="true" type="Tox" factoryName="Tox">
      <option name="ENV_FILES" value="" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <method v="2" />
    </configuration>
    <configuration default="true" type="docker-deploy" factoryName="docker-compose.yml" temporary="true">
      <deployment type="docker-compose.yml">
        <settings />
      </deployment>
      <method v="2" />
    </configuration>
    <configuration default="true" type="docker-deploy" factoryName="docker-image" temporary="true">
      <deployment type="docker-image">
        <settings />
      </deployment>
      <method v="2" />
    </configuration>
    <configuration name="bd-docker-sandbox/docker-compose.yaml.zeppelin: Compose Deployment" type="docker-deploy" factoryName="docker-compose.yml" temporary="true" server-name="Docker">
      <deployment type="docker-compose.yml">
        <settings>
          <option name="services">
            <list>
              <option value="zeppelin" />
            </list>
          </option>
          <option name="sourceFilePath" value="bd-docker-sandbox/docker-compose.yaml" />
        </settings>
      </deployment>
      <method v="2" />
    </configuration>
    <configuration name="bd-hadoop-sandbox/dc-minio.yml.minio: Compose Deployment" type="docker-deploy" factoryName="docker-compose.yml" temporary="true" server-name="Docker">
      <deployment type="docker-compose.yml">
        <settings>
          <option name="services">
            <list>
              <option value="minio" />
            </list>
          </option>
          <option name="sourceFilePath" value="bd-hadoop-sandbox/dc-minio.yml" />
        </settings>
      </deployment>
      <method v="2" />
    </configuration>
    <configuration name="bd-hadoop-sandbox/dc-spark-cluster.yml.spark-notebook: Compose Deployment" type="docker-deploy" factoryName="docker-compose.yml" temporary="true" server-name="Docker">
      <deployment type="docker-compose.yml">
        <settings>
          <option name="services">
            <list>
              <option value="spark-notebook" />
            </list>
          </option>
          <option name="sourceFilePath" value="bd-hadoop-sandbox/dc-spark-cluster.yml" />
        </settings>
      </deployment>
      <method v="2" />
    </configuration>
    <list>
      <item itemvalue="Application.StreamingJob" />
      <item itemvalue="Application.SparkAppWorkflow" />
      <item itemvalue="Application.SparkPi" />
      <item itemvalue="Docker.bd-docker-sandbox/docker-compose.yaml.zeppelin: Compose Deployment" />
      <item itemvalue="Docker.bd-hadoop-sandbox/dc-spark-cluster.yml.spark-notebook: Compose Deployment" />
      <item itemvalue="Docker.bd-hadoop-sandbox/dc-minio.yml.minio: Compose Deployment" />
    </list>
    <recent_temporary>
      <list>
        <item itemvalue="Docker.bd-hadoop-sandbox/dc-spark-cluster.yml.spark-notebook: Compose Deployment" />
        <item itemvalue="Docker.bd-docker-sandbox/docker-compose.yaml.zeppelin: Compose Deployment" />
        <item itemvalue="Application.SparkAppWorkflow" />
        <item itemvalue="Application.SparkPi" />
        <item itemvalue="Docker.bd-hadoop-sandbox/dc-minio.yml.minio: Compose Deployment" />
      </list>
    </recent_temporary>
  </component>
  <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="3bdc845a-73b0-4b8f-9160-c36ec6b5b17f" name="Changes" comment="" />
      <created>1708244105744</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1708244105744</updated>
    </task>
    <task id="LOCAL-00001" summary="2024-02-18 Update Setup Script.">
      <option name="closed" value="true" />
      <created>1708256635960</created>
      <option name="number" value="00001" />
      <option name="presentableId" value="LOCAL-00001" />
      <option name="project" value="LOCAL" />
      <updated>1708256635960</updated>
    </task>
    <task id="LOCAL-00002" summary="2024-02-18 Update Setup Script.">
      <option name="closed" value="true" />
      <created>1708262787101</created>
      <option name="number" value="00002" />
      <option name="presentableId" value="LOCAL-00002" />
      <option name="project" value="LOCAL" />
      <updated>1708262787101</updated>
    </task>
    <task id="LOCAL-00003" summary="2024-02-18 Update Setup Script.">
      <option name="closed" value="true" />
      <created>1708279460213</created>
      <option name="number" value="00003" />
      <option name="presentableId" value="LOCAL-00003" />
      <option name="project" value="LOCAL" />
      <updated>1708279460213</updated>
    </task>
    <task id="LOCAL-00004" summary="2024-02-18 Update Setup Script.">
      <option name="closed" value="true" />
      <created>1708617870809</created>
      <option name="number" value="00004" />
      <option name="presentableId" value="LOCAL-00004" />
      <option name="project" value="LOCAL" />
      <updated>1708617870809</updated>
    </task>
    <task id="LOCAL-00005" summary="2024-02-18 Update Setup Script.">
      <option name="closed" value="true" />
      <created>1708619495842</created>
      <option name="number" value="00005" />
      <option name="presentableId" value="LOCAL-00005" />
      <option name="project" value="LOCAL" />
      <updated>1708619495842</updated>
    </task>
    <task id="LOCAL-00006" summary="2024-02-23 Update kafka config &amp; validation.">
      <option name="closed" value="true" />
      <created>1708651067068</created>
      <option name="number" value="00006" />
      <option name="presentableId" value="LOCAL-00006" />
      <option name="project" value="LOCAL" />
      <updated>1708651067068</updated>
    </task>
    <task id="LOCAL-00007" summary="2024-02-24 Merge Docker Projects.">
      <option name="closed" value="true" />
      <created>1708743039684</created>
      <option name="number" value="00007" />
      <option name="presentableId" value="LOCAL-00007" />
      <option name="project" value="LOCAL" />
      <updated>1708743039684</updated>
    </task>
    <task id="LOCAL-00008" summary="2024-02-24 Merge Docker Projects.">
      <option name="closed" value="true" />
      <created>1708762479910</created>
      <option name="number" value="00008" />
      <option name="presentableId" value="LOCAL-00008" />
      <option name="project" value="LOCAL" />
      <updated>1708762479910</updated>
    </task>
    <task id="LOCAL-00009" summary="2024-02-24 Merge Docker Projects.">
      <option name="closed" value="true" />
      <created>1708764418653</created>
      <option name="number" value="00009" />
      <option name="presentableId" value="LOCAL-00009" />
      <option name="project" value="LOCAL" />
      <updated>1708764418653</updated>
    </task>
    <task id="LOCAL-00010" summary="2024-02-24 Merge Docker Projects.">
      <option name="closed" value="true" />
      <created>1708768699007</created>
      <option name="number" value="00010" />
      <option name="presentableId" value="LOCAL-00010" />
      <option name="project" value="LOCAL" />
      <updated>1708768699007</updated>
    </task>
    <task id="LOCAL-00011" summary="2024-02-24 Merge Docker Projects.">
      <option name="closed" value="true" />
      <created>1708768719300</created>
      <option name="number" value="00011" />
      <option name="presentableId" value="LOCAL-00011" />
      <option name="project" value="LOCAL" />
      <updated>1708768719300</updated>
    </task>
    <task id="LOCAL-00012" summary="2024-02-24 Merge Docker Projects.">
      <option name="closed" value="true" />
      <created>1708769489576</created>
      <option name="number" value="00012" />
      <option name="presentableId" value="LOCAL-00012" />
      <option name="project" value="LOCAL" />
      <updated>1708769489576</updated>
    </task>
    <task id="LOCAL-00013" summary="2024-02-24 Merge Docker Projects.">
      <option name="closed" value="true" />
      <created>1708777785312</created>
      <option name="number" value="00013" />
      <option name="presentableId" value="LOCAL-00013" />
      <option name="project" value="LOCAL" />
      <updated>1708777785312</updated>
    </task>
    <task id="LOCAL-00014" summary="2024-02-24 Merge Docker Projects.">
      <option name="closed" value="true" />
      <created>1708778768889</created>
      <option name="number" value="00014" />
      <option name="presentableId" value="LOCAL-00014" />
      <option name="project" value="LOCAL" />
      <updated>1708778768889</updated>
    </task>
    <task id="LOCAL-00015" summary="2024-02-24 Merge Docker Projects.">
      <option name="closed" value="true" />
      <created>1708778946891</created>
      <option name="number" value="00015" />
      <option name="presentableId" value="LOCAL-00015" />
      <option name="project" value="LOCAL" />
      <updated>1708778946891</updated>
    </task>
    <task id="LOCAL-00016" summary="2024-02-24 Merge Docker Projects.">
      <option name="closed" value="true" />
      <created>1708779422145</created>
      <option name="number" value="00016" />
      <option name="presentableId" value="LOCAL-00016" />
      <option name="project" value="LOCAL" />
      <updated>1708779422145</updated>
    </task>
    <task id="LOCAL-00017" summary="2024-02-24 Merge Docker Projects.">
      <option name="closed" value="true" />
      <created>1708787198522</created>
      <option name="number" value="00017" />
      <option name="presentableId" value="LOCAL-00017" />
      <option name="project" value="LOCAL" />
      <updated>1708787198522</updated>
    </task>
    <task id="LOCAL-00018" summary="2024-02-24 Merge Docker Projects.">
      <option name="closed" value="true" />
      <created>1708791406817</created>
      <option name="number" value="00018" />
      <option name="presentableId" value="LOCAL-00018" />
      <option name="project" value="LOCAL" />
      <updated>1708791406817</updated>
    </task>
    <task id="LOCAL-00019" summary="2024-02-24 Merge Docker Projects.">
      <option name="closed" value="true" />
      <created>1708806465497</created>
      <option name="number" value="00019" />
      <option name="presentableId" value="LOCAL-00019" />
      <option name="project" value="LOCAL" />
      <updated>1708806465497</updated>
    </task>
    <task id="LOCAL-00020" summary="2024-02-25 Change Project Packaging.">
      <option name="closed" value="true" />
      <created>1708831118381</created>
      <option name="number" value="00020" />
      <option name="presentableId" value="LOCAL-00020" />
      <option name="project" value="LOCAL" />
      <updated>1708831118381</updated>
    </task>
    <task id="LOCAL-00021" summary="2024-02-25 Change Project Packaging.">
      <option name="closed" value="true" />
      <created>1708834131543</created>
      <option name="number" value="00021" />
      <option name="presentableId" value="LOCAL-00021" />
      <option name="project" value="LOCAL" />
      <updated>1708834131543</updated>
    </task>
    <task id="LOCAL-00022" summary="2024-02-25 Change Project Packaging.">
      <option name="closed" value="true" />
      <created>1708844951370</created>
      <option name="number" value="00022" />
      <option name="presentableId" value="LOCAL-00022" />
      <option name="project" value="LOCAL" />
      <updated>1708844951370</updated>
    </task>
    <task id="LOCAL-00023" summary="2024-02-25 Change Project Packaging.">
      <option name="closed" value="true" />
      <created>1708859876822</created>
      <option name="number" value="00023" />
      <option name="presentableId" value="LOCAL-00023" />
      <option name="project" value="LOCAL" />
      <updated>1708859876822</updated>
    </task>
    <task id="LOCAL-00024" summary="2024-02-26 Update Confluent Kafka Consumers.">
      <option name="closed" value="true" />
      <created>1708923231301</created>
      <option name="number" value="00024" />
      <option name="presentableId" value="LOCAL-00024" />
      <option name="project" value="LOCAL" />
      <updated>1708923231301</updated>
    </task>
    <task id="LOCAL-00025" summary="2024-02-27 Update Confluent Kafka Consumers.">
      <option name="closed" value="true" />
      <created>1709012432253</created>
      <option name="number" value="00025" />
      <option name="presentableId" value="LOCAL-00025" />
      <option name="project" value="LOCAL" />
      <updated>1709012432253</updated>
    </task>
    <task id="LOCAL-00026" summary="2024-02-27 Update Confluent Kafka Consumers.">
      <option name="closed" value="true" />
      <created>1709051415128</created>
      <option name="number" value="00026" />
      <option name="presentableId" value="LOCAL-00026" />
      <option name="project" value="LOCAL" />
      <updated>1709051415128</updated>
    </task>
    <task id="LOCAL-00027" summary="2024-02-28 Update Confluent Kafka Consumers.">
      <option name="closed" value="true" />
      <created>1709089956280</created>
      <option name="number" value="00027" />
      <option name="presentableId" value="LOCAL-00027" />
      <option name="project" value="LOCAL" />
      <updated>1709089956280</updated>
    </task>
    <task id="LOCAL-00028" summary="2024-02-28 Update Confluent Kafka Consumers.">
      <option name="closed" value="true" />
      <created>1709090852195</created>
      <option name="number" value="00028" />
      <option name="presentableId" value="LOCAL-00028" />
      <option name="project" value="LOCAL" />
      <updated>1709090852195</updated>
    </task>
    <task id="LOCAL-00029" summary="2024-02-28 Update Confluent Kafka Consumers.">
      <option name="closed" value="true" />
      <created>1709140376589</created>
      <option name="number" value="00029" />
      <option name="presentableId" value="LOCAL-00029" />
      <option name="project" value="LOCAL" />
      <updated>1709140376589</updated>
    </task>
    <task id="LOCAL-00030" summary="2024-02-28 Update Confluent Kafka Consumers.">
      <option name="closed" value="true" />
      <created>1709140414437</created>
      <option name="number" value="00030" />
      <option name="presentableId" value="LOCAL-00030" />
      <option name="project" value="LOCAL" />
      <updated>1709140414437</updated>
    </task>
    <task id="LOCAL-00031" summary="2024-02-29 Update Confluent Kafka Consumers.">
      <option name="closed" value="true" />
      <created>1709168318304</created>
      <option name="number" value="00031" />
      <option name="presentableId" value="LOCAL-00031" />
      <option name="project" value="LOCAL" />
      <updated>1709168318304</updated>
    </task>
    <task id="LOCAL-00032" summary="2024-02-29 Update Confluent Kafka Consumers.">
      <option name="closed" value="true" />
      <created>1709175896444</created>
      <option name="number" value="00032" />
      <option name="presentableId" value="LOCAL-00032" />
      <option name="project" value="LOCAL" />
      <updated>1709175896444</updated>
    </task>
    <task id="LOCAL-00033" summary="2024-02-29 Update Confluent Kafka Consumers.">
      <option name="closed" value="true" />
      <created>1709179015706</created>
      <option name="number" value="00033" />
      <option name="presentableId" value="LOCAL-00033" />
      <option name="project" value="LOCAL" />
      <updated>1709179015706</updated>
    </task>
    <task id="LOCAL-00034" summary="2024-02-29 Update Confluent Kafka Consumers.">
      <option name="closed" value="true" />
      <created>1709225198413</created>
      <option name="number" value="00034" />
      <option name="presentableId" value="LOCAL-00034" />
      <option name="project" value="LOCAL" />
      <updated>1709225198413</updated>
    </task>
    <task id="LOCAL-00035" summary="2024-03-01 Update PyTest Cases for utils.">
      <option name="closed" value="true" />
      <created>1709262904292</created>
      <option name="number" value="00035" />
      <option name="presentableId" value="LOCAL-00035" />
      <option name="project" value="LOCAL" />
      <updated>1709262904293</updated>
    </task>
    <task id="LOCAL-00036" summary="2024-03-01 Update PyTest Cases for utils.">
      <option name="closed" value="true" />
      <created>1709277801258</created>
      <option name="number" value="00036" />
      <option name="presentableId" value="LOCAL-00036" />
      <option name="project" value="LOCAL" />
      <updated>1709277801258</updated>
    </task>
    <task id="LOCAL-00037" summary="2024-03-02 Update PyTest Cases for utils.">
      <option name="closed" value="true" />
      <created>1709402263178</created>
      <option name="number" value="00037" />
      <option name="presentableId" value="LOCAL-00037" />
      <option name="project" value="LOCAL" />
      <updated>1709402263178</updated>
    </task>
    <task id="LOCAL-00038" summary="2024-03-02 Update PyTest Cases for utils.">
      <option name="closed" value="true" />
      <created>1709402286740</created>
      <option name="number" value="00038" />
      <option name="presentableId" value="LOCAL-00038" />
      <option name="project" value="LOCAL" />
      <updated>1709402286740</updated>
    </task>
    <task id="LOCAL-00039" summary="2024-09-14 Update Project Configuration.">
      <option name="closed" value="true" />
      <created>1726283371157</created>
      <option name="number" value="00039" />
      <option name="presentableId" value="LOCAL-00039" />
      <option name="project" value="LOCAL" />
      <updated>1726283371157</updated>
    </task>
    <task id="LOCAL-00040" summary="2024-09-14 Update Project Configuration.">
      <option name="closed" value="true" />
      <created>1726284667054</created>
      <option name="number" value="00040" />
      <option name="presentableId" value="LOCAL-00040" />
      <option name="project" value="LOCAL" />
      <updated>1726284667054</updated>
    </task>
    <task id="LOCAL-00041" summary="2024-09-14 Update Project Configuration.">
      <option name="closed" value="true" />
      <created>1726284694294</created>
      <option name="number" value="00041" />
      <option name="presentableId" value="LOCAL-00041" />
      <option name="project" value="LOCAL" />
      <updated>1726284694294</updated>
    </task>
    <task id="LOCAL-00042" summary="2024-09-14 Update Project Configuration.">
      <option name="closed" value="true" />
      <created>1726290251973</created>
      <option name="number" value="00042" />
      <option name="presentableId" value="LOCAL-00042" />
      <option name="project" value="LOCAL" />
      <updated>1726290251973</updated>
    </task>
    <task id="LOCAL-00043" summary="2024-09-14 Update Project Configuration.">
      <option name="closed" value="true" />
      <created>1726291360586</created>
      <option name="number" value="00043" />
      <option name="presentableId" value="LOCAL-00043" />
      <option name="project" value="LOCAL" />
      <updated>1726291360586</updated>
    </task>
    <option name="localTasksCounter" value="44" />
    <servers />
  </component>
  <component name="UnknownFeatures">
    <option featureType="com.intellij.fileTypeFactory" implementationName=".bash_profile" />
    <option featureType="com.intellij.fileTypeFactory" implementationName="*.env" />
    <option featureType="com.intellij.fileTypeFactory" implementationName="*.conf" />
    <option featureType="com.intellij.fileTypeFactory" implementationName="*.profile" />
  </component>
  <component name="Vcs.Log.Tabs.Properties">
    <option name="TAB_STATES">
      <map>
        <entry key="MAIN">
          <value>
            <State />
          </value>
        </entry>
      </map>
    </option>
  </component>
  <component name="VcsManagerConfiguration">
    <MESSAGE value="2024-02-18 Update Setup Script." />
    <MESSAGE value="2024-02-23 Update kafka config &amp; validation." />
    <MESSAGE value="2024-02-24 Merge Docker Projects." />
    <MESSAGE value="2024-02-25 Change Project Packaging." />
    <MESSAGE value="2024-02-26 Update Confluent Kafka Consumers." />
    <MESSAGE value="2024-02-27 Update Confluent Kafka Consumers." />
    <MESSAGE value="2024-02-28 Update Confluent Kafka Consumers." />
    <MESSAGE value="2024-02-29 Update Confluent Kafka Consumers." />
    <MESSAGE value="2024-03-01 Update PyTest Cases for utils." />
    <MESSAGE value="2024-03-02 Update PyTest Cases for utils." />
    <MESSAGE value="2024-09-14 Update Project Configuration." />
    <option name="LAST_COMMIT_MESSAGE" value="2024-09-14 Update Project Configuration." />
  </component>
  <component name="XDebuggerManager">
    <breakpoint-manager>
      <breakpoints>
        <line-breakpoint enabled="true" type="java-line">
          <url>file://$PROJECT_DIR$/bd-java-module/src/main/java/org/examples/hadoop/Main.java</url>
          <line>13</line>
          <option name="timeStamp" value="1" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/bd-python-module/src/main/com/example/kafka/python/kafka_python_simple_consumer.py</url>
          <line>1</line>
          <option name="timeStamp" value="2" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/bd-python-module/src/main/com/example/kafka/confluent/confluent_kafka_simple_consumer.py</url>
          <option name="timeStamp" value="10" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/bd-python-module/src/main/com/example/kafka/confluent/confluent_kafka_DeserializingConsumer.py</url>
          <line>15</line>
          <option name="timeStamp" value="24" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/bd-python-module/src/main/com/example/models/User.py</url>
          <line>84</line>
          <option name="timeStamp" value="30" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/bd-python-module/src/test/test_User.py</url>
          <line>16</line>
          <option name="timeStamp" value="31" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/bd-python-module/src/test/test_User.py</url>
          <line>15</line>
          <option name="timeStamp" value="32" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/bd-python-module/src/test/test_static.py</url>
          <line>11</line>
          <option name="timeStamp" value="35" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/bd-python-module/src/main/com/example/kafka/avro-test.py</url>
          <line>23</line>
          <option name="timeStamp" value="36" />
        </line-breakpoint>
      </breakpoints>
    </breakpoint-manager>
  </component>
</project>