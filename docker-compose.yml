#

#
# docker volume create --name sandbox_apps_path --opt type=none --opt device=/apps --opt o=bind
#
# docker volume create --name sandbox_krb5_stash --opt type=none --opt device=/apps/sandbox/kerberos/stash --opt o=bind
# docker volume create --name sandbox_krb5_principal --opt type=none --opt device=/apps/sandbox/kerberos/principal --opt o=bind
#
# docker volume create --name sandbox_zookeeper_secrets --opt type=none --opt device=/apps/sandbox/zookeeper/hadoop3/secrets --opt o=bind
# docker volume create --name sandbox_zookeeper_data --opt type=none --opt device=/apps/sandbox/zookeeper/hadoop3/data --opt o=bind
# docker volume create --name sandbox_zookeeper_log --opt type=none --opt device=/apps/sandbox/zookeeper/hadoop3/log --opt o=bind
#
# docker volume create --name sandbox_kafka_secrets --opt type=none --opt device=/apps/sandbox/kafka/hadoop3/secrets --opt o=bind
# docker volume create --name sandbox_kafka_data --opt type=none --opt device=/apps/sandbox/kafka/hadoop3/data --opt o=bind
# docker volume create --name sandbox_kafka_log --opt type=none --opt device=/apps/sandbox/kafka/hadoop3/log --opt o=bind
#
# docker volume create --name sandbox_cassandra_data --opt type=none --opt device=/apps/sandbox/cassandra/data --opt o=bind
# docker volume create --name sandbox_cassandra_conf --opt type=none --opt device=/apps/sandbox/cassandra/conf --opt o=bind
#
# docker volume create --name sandbox_hadoop_311 --opt type=none --opt device=/opt/hadoop-3.1.1 --opt o=bind
# docker volume create --name sandbox_hadoop_311_dfs --opt type=none --opt device=/apps/sandbox/hadoop-3.1.1/dfs --opt o=bind
# docker volume create --name sandbox_hadoop_311_yarn --opt type=none --opt device=/apps/sandbox/hadoop-3.1.1/yarn --opt o=bind
# docker volume create --name sandbox_hadoop_311_mapred --opt type=none --opt device=/apps/sandbox/hadoop-3.1.1/mapred --opt o=bind
#
# docker volume create --name sandbox_hive_313 --opt type=none --opt device=/opt/hive-3.1.3 --opt o=bind
# docker volume create --name sandbox_tez_091 --opt type=none --opt device=/opt/tez-0.9.1 --opt o=bind
#
# docker volume create --name sandbox_hbase_246 --opt type=none --opt device=/opt/hbase-2.4.6 --opt o=bind
# docker volume create --name sandbox_hbase_117 --opt type=none --opt device=/opt/hbase-1.1.7 --opt o=bind
#
# docker volume create --name sandbox_nifi_conf --opt type=none --opt device=/apps/sandbox/nifi/conf --opt o=bind
# docker volume create --name sandbox_nifi_content_repository --opt type=none --opt device=/apps/sandbox/nifi/content_repository --opt o=bind
# docker volume create --name sandbox_nifi_database_repository --opt type=none --opt device=/apps/sandbox/nifi/database_repository --opt o=bind
# docker volume create --name sandbox_nifi_flowfile_repository --opt type=none --opt device=/apps/sandbox/nifi/flowfile_repository --opt o=bind
# docker volume create --name sandbox_nifi_provenance_repository --opt type=none --opt device=/apps/sandbox/nifi/provenance_repository --opt o=bind
# docker volume create --name sandbox_nifi_log --opt type=none --opt device=/apps/sandbox/nifi/logs --opt o=bind
# docker volume create --name sandbox_nifi_state --opt type=none --opt device=/apps/sandbox/nifi/state --opt o=bind
#
# docker volume create --name sandbox_airflow_sources --opt type=none --opt device=/apps/sandbox/airflow --opt o=bind
# docker volume create --name sandbox_airflow_dags --opt type=none --opt device=/apps/sandbox/airflow/dags --opt o=bind
# docker volume create --name sandbox_airflow_logs --opt type=none --opt device=/apps/sandbox/airflow/logs --opt o=bind
# docker volume create --name sandbox_airflow_plugins --opt type=none --opt device=/apps/sandbox/airflow/plugins --opt o=bind
#
---
version: "3.9"

services:
  # Kerberos Server
  kdcserver:
    image: brijeshdhaker/kdcserver:22.04
    container_name: kdcserver
    hostname: kdcserver.sandbox.net
    healthcheck:
      test: echo srvr || exit 1
      retries: 20
      interval: 10s
    ports:
      - "749:749"
      - "750:750"
      - "88:88/udp"
    volumes:
      - sandbox_apps_path:/apps
      - /dev/urandom:/dev/random      # This is needed otherwise there won't be enough entropy to generate a new kerberos realm
      - sandbox_krb5_stash:/etc/krb5kdc
      - sandbox_krb5_principal:/var/lib/krb5kdc/
      - ./conf/kerberos:/etc/kerberos
    environment:
      REALM: SANDBOX.NET
      DOMAIN_REALM: sandbox.net
      MASTER_KEY_TYPE: aes256-cts-hmac-sha1-96:normal
      SUPPORTED_ENCRYPTION_TYPES: aes256-cts-hmac-sha1-96:normal aes128-cts-hmac-sha1-96:normal
      KADMIN_PRINCIPAL: kadmin/admin
      KADMIN_PASSWORD: kadmin
      KUSERS_PASSWORD: kuser
    env_file:
      - ./envs/docker_kerberos.env

  #
  nginx:
    image: brijeshdhaker/nginx:1.15.1
    container_name: nginx
    hostname: nginx.sandbox.net
    #map ports you will need
    ports:
      - 80:80
      - 5010:5010
      - 443:443
      - 8001:8001
    #add volume with the keytab file
    volumes:
      - sandbox_apps_path:/apps
      - ./conf/kerberos:/etc/kerberos
      - ./conf/nginx/nginx.conf:/etc/nginx/nginx.conf
    environment:
      KRB5_CONFIG: "/etc/krb5.conf"
#      KRB5_KTNAME: "/apps/security/keytabs/services/spnego.service.keytab"

  # Cassandra Server
  cassandra:
    image: cassandra:4.1
    hostname: cassandra
    container_name: cassandra
    restart: always
    ports:
      - "7000:7000"
      - "7001:7001"  #
      - "7199:7199"  # JMX
      - "9042:9042"  # Native Transport
      - "9160:9160"  # Thrift Clients
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_cassandra_data:/var/lib/cassandra
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  # Zookeeper Server
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    hostname: zookeeper.sandbox.net
    container_name: zookeeper
    healthcheck:
      test: curl -f http://zookeeper.sandbox.net:8080/commands || exit 1
      retries: 20
      interval: 10s
    ports:
      - "2181:2181"
      - "2182:2182"
      - "28080:8080"
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_zookeeper_data:/var/lib/zookeeper/data
      - sandbox_zookeeper_log:/var/lib/zookeeper/log
      - ./conf/kerberos/krb5.conf:/etc/krb5.conf
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SECURE_CLIENT_PORT: 2182
      ZOOKEEPER_TICK_TIME: 2000
      KRB5_CONFIG: "/etc/krb5.conf"
      # ALLOW_UNSIGNED: "true"
      #
      ZOOKEEPER_SERVER_CNXN_FACTORY: org.apache.zookeeper.server.NettyServerCnxnFactory
      ZOOKEEPER_SSL_KEYSTORE_LOCATION: /apps/security/ssl/zookeeper.keystore.jks
      ZOOKEEPER_SSL_KEYSTORE_PASSWORD: confluent
      ZOOKEEPER_SSL_KEYSTORE_TYPE: PKCS12
      ZOOKEEPER_SSL_TRUSTSTORE_LOCATION: /apps/security/ssl/zookeeper.truststore.jks
      ZOOKEEPER_SSL_TRUSTSTORE_PASSWORD: confluent
      ZOOKEEPER_SSL_TRUSTSTORE_TYPE: JKS
      ZOOKEEPER_SSL_CLIENT_AUTH: "need"
      #
      ZOOKEEPER_AUTH_PROVIDER_X509: org.apache.zookeeper.server.auth.X509AuthenticationProvider
      ZOOKEEPER_AUTH_PROVIDER_SASL: org.apache.zookeeper.server.auth.SASLAuthenticationProvider
      #
      KAFKA_OPTS: -Djava.security.auth.login.config=/apps/security/jaas/zookeeper-jaas.conf
        -Djava.security.krb5.conf=/etc/krb5.conf
        -Dsun.security.krb5.debug=false
        -Dkerberos.removeHostFromPrincipal=true
        -Dkerberos.removeRealmFromPrincipal=true
        -Dzookeeper.skipACL=true
        #-Dzookeeper.requireClientAuthScheme=sasl
        #-Dzookeeper.allowSaslFailedClients=false
        #-Dzookeeper.authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
    labels:
      - io.confluent.docker.testing=true
    extra_hosts:
      - "thinkpad.sandbox.net:172.18.0.1"

  # Kafka Broker
  kafkabroker:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafkabroker.sandbox.net
    container_name: kafkabroker
    # restart: on-failure
    healthcheck:
      test: nc kafkabroker.sandbox.net 19091 || exit 1
      retries: 20
      interval: 10s
    depends_on:
      zookeeper:
          condition: service_healthy
    ports:
      - 19091:19091
      - 19092:19092
      - 19093:19093
      - 19094:19094
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_kafka_data:/var/lib/kafka/data
      - /apps/security/ssl:/etc/kafka/secrets
      - ./conf/kerberos/krb5.conf:/etc/krb5.conf
    environment:
      KRB5_CONFIG: "/etc/krb5.conf"
      KAFKA_BROKER_ID: "1"
      KAFKA_BROKER_RACK: "R1"
      KAFKA_JMX_PORT: 9991
      #
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper.sandbox.net:2182'
      KAFKA_ZOOKEEPER_CLIENT_CNXN_SOCKET: org.apache.zookeeper.ClientCnxnSocketNetty
      KAFKA_ZOOKEEPER_SSL_CLIENT_ENABLE: 'true'
      KAFKA_ZOOKEEPER_SSL_KEYSTORE_LOCATION: /apps/security/ssl/kafkabroker.keystore.jks
      KAFKA_ZOOKEEPER_SSL_KEYSTORE_PASSWORD: confluent
      KAFKA_ZOOKEEPER_SSL_KEYSTORE_TYPE: PKCS12
      KAFKA_ZOOKEEPER_SSL_TRUSTSTORE_LOCATION: /apps/security/ssl/kafkabroker.truststore.jks
      KAFKA_ZOOKEEPER_SSL_TRUSTSTORE_PASSWORD: confluent
      KAFKA_ZOOKEEPER_SSL_TRUSTSTORE_TYPE: JKS
      KAFKA_ZOOKEEPER_SET_ACL: 'true'

      # KAFKA_ZOOKEEPER_SSL_CLIENT_ENABLE: 'true'
      # https://docs.confluent.io/platform/current/kafka/multi-node.html#configure-multi-node-environment
      # KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:19092, SASL_SSL://0.0.0.0:19093, EXTERNAL_PLAIN://0.0.0.0:9092, EXTERNAL_SASL://0.0.0.0:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,INTERNAL:SASL_PLAINTEXT,EXTERNAL:SASL_SSL,SSL:SSL
      KAFKA_INTER_BROKER_LISTENER_NAME: EXTERNAL
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafkabroker.sandbox.net:19091,INTERNAL://kafkabroker.sandbox.net:19092,EXTERNAL://kafkabroker.sandbox.net:19093,SSL://kafkabroker.sandbox.net:19094
      #KAFKA_SECURITY_INTER_BROKER_PROTOCOL: SSL
      #
      ## Kerberos / GSSAPI Authentication mechanism
      KAFKA_SASL_KERBEROS_SERVICE_NAME: kafka
      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN,GSSAPI
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: GSSAPI
      #
      ## Listener INTERNAL Configuration
      KAFKA_LISTENER_NAME_INTERNAL_SASL_ENABLED_MECHANISMS: PLAIN
      KAFKA_LISTENER_NAME_INTERNAL_PLAIN_SASL_JAAS_CONFIG: |
        org.apache.kafka.common.security.plain.PlainLoginModule required \
        username="admin" \
        password="admin-secret" \
        user_admin="admin-secret" \
        user_mds="mds-secret";
      #
      ## Listener TOKEN Configuration
      KAFKA_LISTENER_NAME_EXTERNAL_SASL_ENABLED_MECHANISMS: GSSAPI
      KAFKA_LISTENER_NAME_EXTERNAL_GSSAPI_SASL_JAAS_CONFIG: |
        com.sun.security.auth.module.Krb5LoginModule required \
        debug=true \
        useKeyTab=true \
        storeKey=true \
        keyTab="/apps/security/keytabs/services/kafkabroker.keytab" \
        principal="kafka/kafkabroker.sandbox.net@SANDBOX.NET";
      #
      ## SSL Additions
      KAFKA_SSL_KEYSTORE_FILENAME: kafkabroker.keystore.p12
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafkabroker-keystore-creds
      KAFKA_SSL_KEY_CREDENTIALS: kafkabroker-sslkey-creds
      KAFKA_SSL_TRUSTSTORE_FILENAME: kafkabroker.truststore.jks
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: kafkabroker-truststore-creds
      # To enable the broker to authenticate clients (two-way authentication)
      KAFKA_SSL_CLIENT_AUTH: "required"
      # The endpoint identification algorithm used by clients to validate server host name.
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: " "
      #
      KAFKA_LISTENER_NAME_EXTERNAL_SSL_PRINCIPAL_MAPPING_RULES: RULE:^CN=([a-zA-Z0-9.]*).*$$/$$1/ , DEFAULT
      KAFKA_LISTENER_NAME_SSL_SSL_PRINCIPAL_MAPPING_RULES: RULE:^CN=([a-zA-Z0-9.]*).*$$/$$1/ , DEFAULT
      ##
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_OPTS:
        -Djava.security.auth.login.config=/apps/security/jaas/kafkabroker-jaas.conf
        -Djava.security.krb5.conf=/etc/krb5.conf 
        -Dsun.security.krb5.debug=false
        -Dssl.keystore.location=/apps/security/ssl/kafkabroker.keystore.p12
        -Dssl.keystore.password=confluent
        -Dssl.key.password=confluent
        -Dssl.truststore.location=/apps/security/ssl/kafkabroker.truststore.jks
        -Dssl.truststore.password=confluent
      #
      ## Log4J
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,org.apache.kafka=INFO"
      KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
      KAFKA_LOG4J_LOGGER_KAFKA_AUTHORIZER_LOGGER: "INFO, authorizerAppender"
      KAFKA_LOG4J_ADDITIVITY_KAFKA_AUTHORIZER_LOGGER: "false"
      ##
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: https://schemaregistry.sandbox.net:8081
      #KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafkabroker.sandbox.net:19093
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'false'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
    extra_hosts:
      - "thinkpad.sandbox.net:172.18.0.1"

  #
  schemaregistry:
    image: confluentinc/cp-schema-registry:7.5.0
    hostname: schemaregistry.sandbox.net
    container_name: schemaregistry
    depends_on:
      - kafkabroker
    ports:
      - "8081:8081"
    volumes:
      - sandbox_apps_path:/apps
      - ./conf/kerberos/krb5.conf:/etc/krb5.conf
    environment:
      KRB5_CONFIG: "/etc/krb5.conf"
      JAVA_OPTS: |
        -Djava.security.krb5.conf=/etc/krb5.conf 
        -Dsun.security.krb5.debug=false
        -Djavax.net.ssl.keyStore=/apps/security/ssl/schemaregistry.keystore.jks
        -Djavax.net.ssl.keyStorePassword=confluent
        -Djavax.net.ssl.trustStore=/apps/security/ssl/schemaregistry.truststore.jks
        -Djavax.net.ssl.trustStorePassword=confluent
      #
      SCHEMA_REGISTRY_OPTS: "-Djava.security.krb5.conf=/etc/krb5.conf -Dsun.security.krb5.debug=false"
      SCHEMA_REGISTRY_HOST_NAME: schemaregistry.sandbox.net
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafkabroker.sandbox.net:19093'
      # Configure SASL_SSL if SSL encryption is enabled, otherwise configure SASL_PLAINTEXT
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: SASL_SSL
      SCHEMA_REGISTRY_KAFKASTORE_SASL_MECHANISM: GSSAPI
      SCHEMA_REGISTRY_KAFKASTORE_SASL_KERBEROS_SERVICE_NAME: kafka
      SCHEMA_REGISTRY_KAFKASTORE_SASL_JAAS_CONFIG: com.sun.security.auth.module.Krb5LoginModule required
        useKeyTab=true
        storeKey=true
        useTicketCache=false
        keyTab="/apps/security/keytabs/services/schemaregistry.keytab"
        principal="schemaregistry/schemaregistry.sandbox.net@SANDBOX.NET";
      #
      SCHEMA_REGISTRY_LISTENERS: https://0.0.0.0:8081
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: INFO
      #
      SCHEMA_REGISTRY_KAFKASTORE_SSL_TRUSTSTORE_LOCATION: /apps/security/ssl/schemaregistry.truststore.jks
      SCHEMA_REGISTRY_KAFKASTORE_SSL_TRUSTSTORE_PASSWORD: confluent
      SCHEMA_REGISTRY_KAFKASTORE_SSL_KEYSTORE_LOCATION: /apps/security/ssl/schemaregistry.keystore.jks
      SCHEMA_REGISTRY_KAFKASTORE_SSL_KEYSTORE_PASSWORD: confluent
      SCHEMA_REGISTRY_KAFKASTORE_SSL_KEY_PASSWORD: confluent
      SCHEMA_REGISTRY_KAFKASTORE_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "HTTPS"
      #
      SCHEMA_REGISTRY_SSL_TRUSTSTORE_LOCATION: /apps/security/ssl/schemaregistry.truststore.jks
      SCHEMA_REGISTRY_SSL_TRUSTSTORE_PASSWORD: confluent
      SCHEMA_REGISTRY_SSL_KEYSTORE_LOCATION: /apps/security/ssl/schemaregistry.keystore.jks
      SCHEMA_REGISTRY_SSL_KEYSTORE_PASSWORD: confluent
      SCHEMA_REGISTRY_SSL_KEY_PASSWORD: confluent
      SCHEMA_REGISTRY_SSL_CLIENT_AUTH: "true"
      SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "https"
    extra_hosts:
      - "thinkpad.sandbox.net:172.18.0.1"

  #
  kafkaclient:
    image: brijeshdhaker/kafka-clients:7.5.0
    hostname: kafkaclient.sandbox.net
    container_name: kafkaclient
    restart: on-failure
    command: sleep infinity
    volumes:
      - sandbox_apps_path:/apps
      - ./conf/kerberos/krb5.conf:/etc/krb5.conf
    environment:
      KRB5_CONFIG: "/etc/krb5.conf"
    extra_hosts:
      - "thinkpad.sandbox.net:172.18.0.1"

  #
  # HDFS Cluster
  #
  namenode:
    image: brijeshdhaker/hadoop-namenode:3.1.1
    build:
      context: .
      dockerfile: docker-hadoop/namenode/Dockerfile
    container_name: namenode
    hostname: namenode.sandbox.net
    restart: no
    ports:
      - "9870:9870"   # http
      - "9871:9871"   # https
      - "9000:9000"   # hdfs
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_hadoop_311_dfs:/hadoop/dfs
    environment:
      CLUSTER_NAME: "docker-sandbox"
      MULTIHOMED_NETWORK: 2
    env_file:
      - envs/docker_hadoop.env

  #
  datanode:
    image: brijeshdhaker/hadoop-datanode:3.1.1
    build:
      context: .
      dockerfile: docker-hadoop/datanode/Dockerfile
    container_name: datanode
    hostname: datanode.sandbox.net
    ports:
      - "9864:9864"   # http
      - "9865:9865"   # https
      - "9866:9866"
    restart: no
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_hadoop_311_dfs:/hadoop/dfs
    environment:
      CLUSTER_NAME: "docker-sandbox"
      SERVICE_PRECONDITION: "namenode.sandbox.net:9000"
    env_file:
      - envs/docker_hadoop.env

  #
  # YARN Cluster
  #
  resourcemanager:
    image: brijeshdhaker/hadoop-resourcemanager:3.1.1
    build:
      context: .
      dockerfile: docker-hadoop/resourcemanager/Dockerfile
    container_name: resourcemanager
    hostname: resourcemanager.sandbox.net
    healthcheck:
      test: curl -f http://resourcemanager.sandbox.net:8088 || exit 1
      retries: 20
      interval: 10s
    restart: no
    ports:
      - "8088:8088"
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_hadoop_311_yarn:/yarn
    environment:
      SERVICE_PRECONDITION: "namenode.sandbox.net:9000 namenode.sandbox.net:9870"
    env_file:
      - envs/docker_hadoop.env

  #
  nodemanager:
    image: brijeshdhaker/hadoop-nodemanager:3.1.1
    build:
      context: .
      dockerfile: docker-hadoop/nodemanager/Dockerfile
    container_name: nodemanager
    hostname: nodemanager.sandbox.net
    restart: no
    ports:
      - "8042:8042"
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_hadoop_311_yarn:/yarn
    environment:
      HADOOP_CONF_DIR: "/etc/yarn/conf"
      YARN_SITE_DIR: "/etc/yarn/conf"
      SERVICE_PRECONDITION: "resourcemanager.sandbox.net:8088"
    env_file:
      - envs/docker_hadoop.env

  # YARN Timeline Server
  timelineserver:
    image: brijeshdhaker/hadoop-timelineserver:3.1.1
    build:
      context: .
      dockerfile: docker-hadoop/timelineserver/Dockerfile
    container_name: timelineserver
    hostname: timelineserver.sandbox.net
    restart: no
    ports:
      - "8188:8188"
    environment:
      SERVICE_PRECONDITION: "namenode.sandbox.net:9000"
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_hadoop_311_yarn:/yarn
    env_file:
      - envs/docker_hadoop.env

  # MR History Server
  historyserver:
    image: brijeshdhaker/hadoop-historyserver:3.1.1
    build:
      context: .
      dockerfile: docker-hadoop/historyserver/Dockerfile
    container_name: historyserver
    hostname: historyserver.sandbox.net
    restart: no
    ports:
      - "19888:19888"
    environment:
      SERVICE_PRECONDITION: "namenode.sandbox.net:9000 namenode.sandbox.net:9870"
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_hadoop_311_mapred:/mapred
    env_file:
      - envs/docker_hadoop.env

  #
  # Mysql Server
  #
  mysqlserver:
    image: mysql/mysql-server:8.0.28
    container_name: mysqlserver
    hostname: mysqlserver.sandbox.net
    restart: always
    ports:
      - "3306:3306"
    command: "mysqld --character-set-server=utf8 --collation-server=utf8_unicode_ci"
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_mysql_data:/var/lib/mysql
      - ./conf/mysql:/etc/mysql/conf.d
    env_file:
      - ./envs/docker_mysql.env
    healthcheck:
      test: "/usr/bin/mysql --user=root --password=p@SSW0rd --execute \"SHOW DATABASES;\""
      # test: [ "CMD", "mysqladmin" ,"ping", "-h", "localhost" ]
      timeout: 20s
      retries: 10

  #
  # Hive Metastore
  #
  metastore:
    image: brijeshdhaker/hive:3.1.3
    hostname: metastore.sandbox.net
    container_name: metastore
    healthcheck:
      test: netstat -lpn | grep 9083 || exit 1
      retries: 20
      interval: 10s
    env_file:
      - ./envs/docker_hive.env
      - ./envs/docker_clients.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "mysqlserver.sandbox.net:3306"
    ports:
      - "9083:9083"
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_hadoop_311:/opt/hadoop
      - ./conf/hadoop/client:/opt/hadoop/etc/hadoop

  # Hive Server
  hiveserver:
    image: brijeshdhaker/hive:3.1.3
    container_name: hiveserver
    hostname: hiveserver.sandbox.net
    healthcheck:
      test: nc -vz hiveserver.sandbox.net 10002 || exit 1
      retries: 20
      interval: 10s
    depends_on:
      metastore:
        condition: service_healthy
    env_file:
      - ./envs/docker_hive.env
      - ./envs/docker_clients.env
    environment:
      SERVICE_PRECONDITION: "namenode.sandbox.net:9000 metastore.sandbox.net:9083"
    ports:
      - "10000:10000"
      - "10002:10002"
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_hadoop_311:/opt/hadoop
      - ./conf/hadoop/client:/opt/hadoop/etc/hadoop
      - sandbox_tez_091:/opt/tez
      - ./conf/tez/tez-site.xml:/opt/tez/conf/tez-site.xml

  # Hive Tez UI
  hivetezui:
    image: brijeshdhaker/tezui:0.9.1
    container_name: hivetezui
    hostname: hivetezui.sandbox.net
    healthcheck:
      test: nc -vz hivetezui.sandbox.net 9999 || exit 1
      retries: 20
      interval: 10s
    depends_on:
      timelineserver:
        condition: service_healthy
    environment:
      KRB5_CONFIG: "/etc/krb5.conf"
      SERVICE_PRECONDITION: "timelineserver.sandbox.net:8188"
    ports:
      - "9999:9999"
    volumes:
      - sandbox_apps_path:/apps

  #
  # Hbase Cluster
  #
  hmaster:
    image: brijeshdhaker/hbase-master:2.4.6
    hostname: hmaster.sandbox.net
    container_name: hmaster
    healthcheck:
      test: curl -f http://hmaster.sandbox.net:16010 || exit 1
      retries: 20
      interval: 10s
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      SERVICE_PRECONDITION: "namenode.sandbox.net:9870 zookeeper.sandbox.net:2181"
    env_file:
      - envs/docker_hbase.env
      - envs/docker_clients.env
    ports:
      - "16000:16000"
      - "16010:16010"
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_hadoop_311:/opt/hadoop
      - ./conf/hadoop/client:/opt/hadoop/etc/hadoop
      - ./conf/hbase/zookeeper-jaas.conf:/opt/hbase/conf/zookeeper-jaas.conf

  #
  hregion:
    image: brijeshdhaker/hbase-regionserver:2.4.6
    hostname: hregion.sandbox.net
    container_name: hregion
    healthcheck:
      test: curl -f http://hregion.sandbox.net:16030 || exit 1
      retries: 20
      interval: 10s
    env_file:
      - envs/docker_hbase.env
      - envs/docker_clients.env
    environment:
      SERVICE_PRECONDITION: "namenode.sandbox.net:9870 zookeeper.sandbox.net:2181 hmaster.sandbox.net:16010"
    ports:
      - "16020:16020"
      - "16030:16030"
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_hadoop_311:/opt/hadoop
      - ./conf/hadoop/client:/opt/hadoop/etc/hadoop
      - ./conf/kerberos:/etc/kerberos
#      - ./conf/hbase/hbase-env.sh:/opt/hbase/conf/hbase-env.sh
      - ./conf/hbase/zookeeper-jaas.conf:/opt/hbase/conf/zookeeper-jaas.conf
      - ./conf/hbase/hbase-site.xml:/opt/hbase/conf/hbase-site.xml

  #
  # Spark History Server
  #
  sparkhistory:
    image: brijeshdhaker/spark:3.1.3
    container_name: sparkhistory
    hostname: sparkhistory.sandbox.net
    healthcheck:
      test: curl -f http://sparkhistory.sandbox.net:18080 || exit 1
      retries: 20
      interval: 10s
    environment:
      SPARK_WORKLOAD: HistoryServer
      SERVICE_PRECONDITION: "namenode.sandbox.net:9000 namenode.sandbox.net:9870"
    depends_on:
      namenode:
        condition: service_healthy
      datanode:
        condition: service_healthy
    ports:
      - "18080:18080"
    env_file:
      - ./envs/docker_clients.env
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_hadoop_311:/opt/hadoop
      - ./conf/hadoop/client:/opt/hadoop/etc/hadoop
      - ./conf/kerberos:/etc/kerberos
      - ./conf/spark/spark-env.sh:/opt/spark/conf/spark-env.sh
      - ./conf/spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf

  #
  # Gateway Node
  #
  gateway:
    image: brijeshdhaker/ubuntu:22.04
    container_name: gateway
    hostname: gateway.sandbox.net
    healthcheck:
      test: nc -vz gateway.sandbox.net 22 || exit 1
      retries: 20
      interval: 10s
    restart: always
    command:
      - "/usr/sbin/sshd -D"
    ports:
      - "2222:22"
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_hadoop_311:/opt/hadoop
      - ./conf/hadoop/client:/opt/hadoop/etc/hadoop
      - sandbox_hbase_246:/opt/hbase
      - ./conf/hbase:/opt/hbase/conf
      - sandbox_hive_313:/opt/hive
      - ./conf/hive/client/hive-site.xml:/opt/hive/conf/hive-site.xml
      - sandbox_tez_091:/opt/tez
      - ./conf/tez/tez-site.xml:/opt/tez/conf/tez-site.xml
      - sandbox_spark_312:/opt/spark
      - /opt/flink-1.12.2:/opt/flink
      - sandbox_maven_363:/opt/maven-3.6.3
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
    env_file:
      - ./envs/docker_clients.env

  #
  # Zeppelin Notebook
  #
  zeppelin:
    image: apache/zeppelin:0.10.1
    container_name: zeppelin
    hostname: zeppelin.sandbox.net
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
    env_file:
      - ./envs/docker_clients.env
    ports:
      - "9080:8080"
      - "9081:8081"
    volumes:
      - sandbox_apps_path:/apps
      - ./conf/kerberos/krb5.conf:/etc/krb5.conf
      - /opt/zeppelin/conf:/opt/zeppelin/conf
      - sandbox_hadoop_311:/opt/hadoop
      - ./conf/hadoop/client:/opt/hadoop/etc/hadoop
      - sandbox_hbase_246:/opt/hbase
      - sandbox_hbase_117:/opt/hbase-client
      - ./conf/hbase:/opt/hbase/conf
      - sandbox_hive_313:/opt/hive
      - ./conf/hive/client:/etc/hive/conf
      - sandbox_tez_091:/opt/tez
      - /opt/flink-1.12.2:/opt/flink
      - sandbox_spark_312:/opt/spark
      - sandbox_zeppelin_notebook:/opt/notebook
  #
  # Apache NiFi
  #
  nififlow:
    image: hortonworks/nifi:latest
    container_name: nififlow
    hostname: nififlow
    restart: always
    ports:
      - "19090:8080"
      - "19443:8443"
    volumes:
      - sandbox_apps_path:/apps
      - sandbox_nifi_conf:/opt/nifi/nifi-current/conf
      - sandbox_nifi_content_repository:/opt/nifi/nifi-current/content_repository
      - sandbox_nifi_database_repository:/opt/nifi/nifi-current/database_repository
      - sandbox_nifi_flowfile_repository:/opt/nifi/nifi-current/flowfile_repository
      - sandbox_nifi_provenance_repository:/opt/nifi/nifi-current/provenance_repository
      - sandbox_nifi_log:/opt/nifi/nifi-current/logs
      - sandbox_nifi_state:/opt/nifi/nifi-current/state

#
#
#
volumes:
  #
  sandbox_apps_path:
    external: true
  #
  sandbox_krb5_stash:
    external: true
  sandbox_krb5_principal:
    external: true
  #
  sandbox_maven_363:
    external: true
  sandbox_m2:
    external: true
  sandbox_ivy2:
    external: true
  #
  sandbox_hadoop_311:
    external: true
  sandbox_hadoop_311_dfs:
    external: true
  sandbox_hadoop_311_mapred:
    external: true
  sandbox_hadoop_311_yarn:
    external: true
  #
  sandbox_mysql_data:
    external: true
  sandbox_mysql_conf:
    external: true
  #
  sandbox_zeppelin:
    external: true
  sandbox_zeppelin_notebook:
    external: true
  #
  sandbox_zookeeper_secrets:
    external: true
  sandbox_zookeeper_data:
    external: true
  sandbox_zookeeper_log:
    external: true
  #
  sandbox_kafka_secrets:
    external: true
  sandbox_kafka_data:
    external: true
  sandbox_kafka_log:
    external: true
  #
  sandbox_cassandra_data:
    external: true
  sandbox_cassandra_conf:
    external: true
  #
  sandbox_hbase_246:
    external: true
  sandbox_hbase_117:
    external: true
  #
  sandbox_hive_313:
    external: true
  sandbox_tez_091:
    external: true
  #
  sandbox_spark_312:
    external: true
  #
  sandbox_nifi_conf:
    external: true
  sandbox_nifi_content_repository:
    external: true
  sandbox_nifi_database_repository:
    external: true
  sandbox_nifi_flowfile_repository:
    external: true
  sandbox_nifi_provenance_repository:
    external: true
  sandbox_nifi_log:
    external: true
  sandbox_nifi_state:
    external: true
  #
  sandbox_airflow_sources:
    external: true
  sandbox_airflow_dags:
    external: true
  sandbox_airflow_logs:
    external: true
  sandbox_airflow_plugins:
    external: true

#
networks:
  default:
    external: true
    driver: bridge
    name: sandbox.net
