#
#spark.jars.packages                                 org.apache.spark:spark-hadoop-cloud_2.12:3.5.0,org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.4.3,org.apache.iceberg:iceberg-aws-bundle:1.4.3
#spark.jars                                          /opt/spark/jars/iceberg-aws-bundle-1.4.3.jar,/opt/spark/jars/iceberg-spark-runtime-3.5_2.12-1.4.3.jar
spark.jars.ivy                                      /apps/.ivy2

#
spark.kerberos.principal                            spark@SANDBOX.NET
spark.kerberos.keytab                               /apps/security/keytabs/users/spark.keytab
spark.security.credentials.hive.enabled             false
spark.security.credentials.hbase.enabled            false

#
spark.driver.memory                                 640m
spark.driver.cores                                  1
spark.executor.memory                               640m
spark.executor.cores                                1

#
spark.yarn.queue                                    engineering
spark.yarn.archive                                  hdfs://namenode:9000/archives/spark/spark-3.5.0.zip
spark.yarn.dist.archives                            hdfs://namenode:9000/archives/pyspark/pyspark37-20221125.tar.gz#environment
spark.yarn.dist.files                               /opt/spark/conf/log4j.properties
spark.yarn.jars                                     hdfs://namenode.sandbox.net:9000/archives/iceberg/iceberg-spark-runtime-3.5_2.12-1.4.3.jar,hdfs://namenode.sandbox.net:9000/archives/iceberg/iceberg-aws-bundle-1.4.3.jar
spark.yarn.historyServer.allowTracking              true

#
spark.webui.yarn.useProxy                           true
spark.eventLog.enabled                              true
spark.eventLog.dir                                  /apps/var/logs/spark

#
spark.yarn.am.extraJavaOptions                      '-Divy.home=/apps/.ivy2 -Djava.security.krb5.conf=/etc/krb5.conf -DAWS_ACCESS_KEY_ID=pgm2H2bR7a5kMc5XCYdO -DAWS_SECRET_ACCESS_KEY=zjd8T0hXFGtfemVQ6AH3yBAPASJNXNbVSx5iddqG'
spark.driver.extraJavaOptions                       '-Divy.home=/apps/.ivy2 -Djava.security.krb5.conf=/etc/krb5.conf -DAWS_ACCESS_KEY_ID=pgm2H2bR7a5kMc5XCYdO -DAWS_SECRET_ACCESS_KEY=zjd8T0hXFGtfemVQ6AH3yBAPASJNXNbVSx5iddqG'
spark.executor.extraJavaOptions                     '-Divy.home=/apps/.ivy2 -Djava.security.krb5.conf=/etc/krb5.conf -DAWS_ACCESS_KEY_ID=pgm2H2bR7a5kMc5XCYdO -DAWS_SECRET_ACCESS_KEY=zjd8T0hXFGtfemVQ6AH3yBAPASJNXNbVSx5iddqG'

#
spark.sql.extensions                                org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.spark_catalog                     org.apache.iceberg.spark.SparkSessionCatalog
spark.sql.catalog.spark_catalog.type                hive
spark.sql.catalog.iceberg                           org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.iceberg.type                      hadoop
spark.sql.catalog.iceberg.warehouse                 s3a://openlake/warehouse/
spark.sql.catalog.iceberg.s3.endpoint               http://minio.sandbox.net:9010
spark.sql.defaultCatalog                            iceberg
spark.sql.catalogImplementation                     hive

#
spark.hadoop.fs.s3a.endpoint                        http://minio.sandbox.net:9010
spark.hadoop.fs.s3a.access.key                      pgm2H2bR7a5kMc5XCYdO
spark.hadoop.fs.s3a.secret.key                      zjd8T0hXFGtfemVQ6AH3yBAPASJNXNbVSx5iddqG
spark.hadoop.fs.s3a.path.style.access               true
spark.hadoop.fs.s3a.aws.credentials.provider        org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider 
spark.hadoop.fs.s3a.impl                            org.apache.hadoop.fs.s3a.S3AFileSystem