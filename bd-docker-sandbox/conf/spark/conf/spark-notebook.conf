# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"
# spark.jars.packages              org.apache.hadoop:hadoop-aws:3.3.4

#
spark.master                                                spark://spark-master.sandbox.net:7077
spark.jars.ivy                                              /apps/.ivy2
spark.jars.packages                                         org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1,org.apache.spark:spark-hadoop-cloud_2.12:3.4.1,org.apache.hadoop:hadoop-aws:3.3.4

#
spark.driver.memory                                         1g
spark.driver.cores                                          1
spark.executor.instances                                    2
spark.executor.memory                                       1g
spark.executor.cores                                        2

#
spark.hadoop.hive.cli.print.header                          true

spark.eventLog.enabled                                      true
spark.eventLog.dir                                          /apps/var/logs/spark-events
spark.history.fs.logDirectory                               /apps/var/logs/spark-events

#
# spark.hadoop.fs.defaultFS                                   s3a://warehouse-hadoop/
spark.hadoop.fs.s3a.endpoint                                http://minio.sandbox.net:9010
spark.hadoop.fs.s3a.access.key                              pgm2H2bR7a5kMc5XCYdO
spark.hadoop.fs.s3a.secret.key                              zjd8T0hXFGtfemVQ6AH3yBAPASJNXNbVSx5iddqG
spark.hadoop.fs.s3a.path.style.access                       true
spark.hadoop.fs.s3a.aws.credentials.provider                org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
spark.hadoop.fs.s3a.impl                                    org.apache.hadoop.fs.s3a.S3AFileSystem

#
spark.driver.extraJavaOptions                               '-Divy.home=/apps/.ivy2 -Djava.security.krb5.conf=/etc/krb5.conf -DAWS_ACCESS_KEY_ID=pgm2H2bR7a5kMc5XCYdO -DAWS_SECRET_ACCESS_KEY=zjd8T0hXFGtfemVQ6AH3yBAPASJNXNbVSx5iddqG'
spark.executor.extraJavaOptions                             '-Divy.home=/apps/.ivy2 -Djava.security.krb5.conf=/etc/krb5.conf -DAWS_ACCESS_KEY_ID=pgm2H2bR7a5kMc5XCYdO -DAWS_SECRET_ACCESS_KEY=zjd8T0hXFGtfemVQ6AH3yBAPASJNXNbVSx5iddqG'
