#
#
#
CLUSTER_NAME=docker-sandbox
MULTIHOMED_NETWORK=2

#
#
#
JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/
M2_HOME=/opt/maven-3.6.3

#
#
#
AIRFLOW_UID=50000

#
# Python
#
PYSPARK_PYTHON=/opt/conda/envs/pyspark37/bin/python
PYSPARK_DRIVER_PYTHON=/opt/conda/envs/pyspark37/bin/python

#
# MySql Server
#
MYSQL_OPERATIONS_USER=operate
MYSQL_OPERATIONS_PASSWORD=p@SSW0rd
MYSQL_ROOT_PASSWORD=p@SSW0rd
MYSQL_DATABASE=PUBLIC
MYSQL_USER=superuser
MYSQL_PASSWORD=p@SSW0rd
MYSQL_ROOT_HOST=172.18.0.1

#
# Kerberos
#
KRB5_CONFIG="/etc/krb5.conf"
# KRB5CCNAME="FILE:$HOME/krb5cc_$(id -u)"
# KINIT_KEYTAB=/apps/security/keytabs/services/hdfs.service.keytab
# KINIT_PRINCIPAL=hdfs/_HOST@SANDBOX.NET

#
# HADOOP
#
HADOOP_VERSION=3.3.4
HADOOP_HOME=/opt/hadoop
HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
HADOOP_COMMON_HOME=/opt/hadoop
HADOOP_MAPRED_HOME=/opt/hadoop
HADOOP_LOG_DIR=/apps/var/log/hadoop
HADOOP_OPTS="-Djava.library.path=/opt/hadoop/lib/native -Djava.security.krb5.conf=/etc/krb5.conf"
HADOOP_CLIENT_OPTS="-Djava.security.krb5.conf=/etc/krb5.conf"

#
#
#
YARN_HOME=/opt/hadoop
YARN_CONF_DIR=/opt/hadoop/etc/hadoop
YARN_LOG_DIR=/apps/var/log/yarn
YARN_OPTS="-Djava.security.krb5.conf=/etc/krb5.conf"

#
MAPRED_HISTORYSERVER_OPTS="-Djava.security.krb5.conf=/etc/krb5.conf -Dsun.security.krb5.debug=false -Dsun.security.spnego.debug"
HADOOP_JOB_HISTORYSERVER_OPTS="-Djava.library.path=/opt/hadoop/lib/native -Djava.security.krb5.conf=/etc/krb5.conf -Djava.security.krb5.realm=SANDBOX.NET -Dsun.security.krb5.debug=true -Djava.security.krb5.kdc=kdcserver.sandbox.net"

#
#
#
HBASE_HOME=/opt/hbase
#HBASE_OPTS="-Dhbase.log.dir=/apps/var/log/hbase -Djava.security.auth.login.config=/apps/security/jaas/hbase-jaas.conf"

#
#
#
HIVE_HOME=/opt/hive
HIVE_CONF_DIR=/opt/hive/conf

#
#
#
TEZ_HOME=/opt/tez
TEZ_CONF_DIR=/opt/tez/conf

#
# Spark
#
SPARK_HOME=/opt/spark
SPARK_MASTER=spark://spark-master:7077
SPARK_MASTER_WEBUI_PORT=8080
SPARK_MASTER_LOG=/apps/var/log/spark/spark-master.out
#
SPARK_WORKER_PORT=7000
SPARK_WORKER_WEBUI_PORT=8080
SPARK_WORKER_LOG=/apps/var/log/spark/spark-worker.out
#
SPARK_HISTORY_CONF_FILE=/opt/spark/conf/spark-defaults.conf

#
# Zeppelin variables
#
ZEPPELIN_LOG_DIR=/apps/var/log/zeppelin
ZEPPELIN_NOTEBOOK_DIR=/opt/notebook
USE_HADOOP=true
FLINK_HOME=/opt/flink
PATH=/opt/conda/envs/python_3_with_R/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/hadoop/bin:/opt/hadoop/sbin

#
# Minio S3
#
AWS_S3_ENDPOINT=http://minio.sandbox.net:9010
AWS_ACCESS_KEY_ID=ffaJ6a2MOj8mZ5lI3P6h
AWS_SECRET_ACCESS_KEY=9u8TCmTtg9VyCVzgfDl6LvgcDd84DaM4h43bg1Bs
AWS_REGION=us-east-1