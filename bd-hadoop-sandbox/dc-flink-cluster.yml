#
# docker volume create --name sandbox_flink_data --opt type=none --opt device=/apps/sandbox/flink/data --opt o=bind
#
#
# docker compose -f bd-hadoop-sandbox/docker-compose.yml up -d
# docker compose -f bd-hadoop-sandbox/docker-compose.yml down
#

#
# docker compose -f bd-hadoop-sandbox/dc-flink-cluster.yml up -d
# docker compose -f bd-hadoop-sandbox/dc-flink-cluster.yml down
#
version: "3.9"

#
include:
  - path: ../bd-hadoop-sandbox/dc-kafka-cluster-7.5.2.yml
  - path: ../bd-hadoop-sandbox/dc-minio.yml
#  - path: ../bd-hadoop-sandbox/dc-hive-cluster.yml

#
services:
  ##
  flink-jobmanager:
    image: flink:1.20.0-scala_2.12-java17
    hostname: flink-jobmanager
    container_name: flink-jobmanager
    command: "jobmanager.sh start-foreground"
    depends_on:
      kafkabroker:
        condition: service_healthy
    ports:
      - "8881:8081"
    healthcheck:
      test: curl -f http://flink-jobmanager:8081 || exit 1
      retries: 20
      interval: 10s
    volumes:
      - sandbox_apps_path:/apps
#      - sandbox_hadoop_334:/opt/hadoop
#      - ./conf/hadoop/client:/opt/hadoop/etc/hadoop
#      - sandbox_hive_313:/opt/hive
#      - ./conf/hive/client/hive-site.xml:/opt/hive/conf/hive-site.xml
      - ./conf/flink/config.yaml:/opt/flink/conf/config.yaml
      - ./conf/kerberos/krb5.conf:/etc/krb5.conf
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
#      - HADOOP_HOME=/opt/hadoop
#      - HIVE_HOME=/opt/hive
#      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
#      - HADOOP_CLASSPATH=/opt/hadoop/etc/hadoop:/opt/hive/lib/hive-*.jar:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*
#      - PATH=/opt/flink/bin:/opt/java/openjdk/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/hadoop/bin:/opt/hadoop/sbin


  ##
  flink-taskmanager:
    image: flink:1.20.0-scala_2.12-java17
    hostname: flink-taskmanager
    container_name: flink-taskmanager
    command: "taskmanager.sh start-foreground"
    depends_on:
      flink-jobmanager:
        condition: service_healthy
    healthcheck:
      test: echo $HOSTNAME || exit 1
      retries: 20
      interval: 10s
    volumes:
      - sandbox_apps_path:/apps
#      - sandbox_hadoop_334:/opt/hadoop
#      - ./conf/hadoop/client:/opt/hadoop/etc/hadoop
#      - sandbox_hive_313:/opt/hive
#      - ./conf/hive/client/hive-site.xml:/opt/hive/conf/hive-site.xml
      - ./conf/flink/config.yaml:/opt/flink/conf/config.yaml
      - ./conf/kerberos/krb5.conf:/etc/krb5.conf
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
      - JOB_MANAGER_RPC_PORT=6123
#      - HADOOP_HOME=/opt/hadoop
#      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
#      - HADOOP_CLASSPATH=/opt/hadoop/etc/hadoop:/opt/hive/lib/*:/opt/hadoop/share/hadoop/common/lib/*:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoop/share/hadoop/hdfs/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/yarn/*
#      - PATH=/opt/flink/bin:/opt/java/openjdk/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/hadoop/bin:/opt/hadoop/sbin
#      - FLINK_NUM_TASK_SLOTS=2


#
volumes:
  #
  sandbox_apps_path:
    external: true
  sandbox_security_secrets:
    external: true
  #
  sandbox_hadoop_334:
    external: true
  #
  sandbox_flink_data:
    external: true

#
networks:
  default:
    external: true
    driver: bridge
    name: sandbox.net
