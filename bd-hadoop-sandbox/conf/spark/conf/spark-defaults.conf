#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"

#
spark.master                                                spark://spark-master.sandbox.net:7077
spark.jars.ivy                                              /apps/.ivy2

#
spark.driver.memory                                         1024m
spark.driver.cores                                          1
spark.executor.instances                                    2
spark.executor.memory                                       1024m
spark.executor.cores                                        2

#
spark.hadoop.hive.cli.print.header                          true

spark.eventLog.enabled                                      true
spark.eventLog.dir                                          /apps/var/logs/spark-events
spark.history.fs.logDirectory                               /apps/var/logs/spark-events

#
# spark.hadoop.fs.defaultFS                                   s3a://warehouse-hadoop/
spark.hadoop.fs.s3a.endpoint                                http://minio.sandbox.net:9010
spark.hadoop.fs.s3a.access.key                              pgm2H2bR7a5kMc5XCYdO
spark.hadoop.fs.s3a.secret.key                              zjd8T0hXFGtfemVQ6AH3yBAPASJNXNbVSx5iddqG
spark.hadoop.fs.s3a.path.style.access                       true
spark.hadoop.fs.s3a.aws.credentials.provider                org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
spark.hadoop.fs.s3a.impl                                    org.apache.hadoop.fs.s3a.S3AFileSystem

#
spark.driver.extraJavaOptions                               '-Divy.home=/apps/.ivy2 -Djava.security.krb5.conf=/etc/krb5.conf -DAWS_ACCESS_KEY_ID=pgm2H2bR7a5kMc5XCYdO -DAWS_SECRET_ACCESS_KEY=zjd8T0hXFGtfemVQ6AH3yBAPASJNXNbVSx5iddqG'
spark.executor.extraJavaOptions                             '-Divy.home=/apps/.ivy2 -Djava.security.krb5.conf=/etc/krb5.conf -DAWS_ACCESS_KEY_ID=pgm2H2bR7a5kMc5XCYdO -DAWS_SECRET_ACCESS_KEY=zjd8T0hXFGtfemVQ6AH3yBAPASJNXNbVSx5iddqG'
