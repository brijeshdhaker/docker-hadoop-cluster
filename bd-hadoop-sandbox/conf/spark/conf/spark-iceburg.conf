#
spark.jars.ivy                                              /apps/.ivy2
spark.jars.packages                                         org.apache.hadoop:hadoop-aws:3.0.0
spark.master                                                spark://spark-iceberg.sandbox.net:7077

# org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1,mysql:mysql-connector-java:8.0.33

#
spark.sql.extensions                                        org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.spark_catalog                             org.apache.iceberg.spark.SparkSessionCatalog
spark.sql.catalog.spark_catalog.type                        hive

#
spark.sql.catalog.hadoop_prod                               org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.hadoop_prod.type                          hadoop
spark.sql.catalog.hadoop_prod.warehouse                     s3a://warehouse-hadoop/

#
spark.sql.catalog.rest_prod                                 org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.rest_prod.type                            rest
spark.sql.catalog.rest_prod.uri                             http://rest.sandbox.net:8181
spark.sql.catalog.rest_prod.io-impl                         org.apache.iceberg.aws.s3.S3FileIO
spark.sql.catalog.rest_prod.warehouse                       s3://warehouse-rest/
spark.sql.catalog.rest_prod.s3.endpoint                     http://minio:9010

#
spark.sql.catalog.mysql_prod                                org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.mysql_prod.catalog-impl                   org.apache.iceberg.jdbc.JdbcCatalog
spark.sql.catalog.mysql_prod.uri                            jdbc:mysql://mysqlserver.sandbox.net:3306/ICEBERG_CATALOG
spark.sql.catalog.mysql_prod.jdbc.user                      mysqladmin
spark.sql.catalog.mysql_prod.jdbc.password                  mysqladmin
spark.sql.catalog.mysql_prod.warehouse                      s3a://warehouse-jdbc/

#
spark.sql.defaultCatalog                                    hadoop_prod
spark.sql.catalogImplementation                             in-memory
spark.hadoop.hive.cli.print.header                          true

#
spark.eventLog.enabled                                      true
spark.eventLog.dir                                          /home/iceberg/spark-events
spark.history.fs.logDirectory                               /home/iceberg/spark-events


#
# spark.hadoop.fs.defaultFS                                   s3a://warehouse-hadoop/
spark.hadoop.fs.s3a.endpoint                                http://minio.sandbox.net:9010
spark.hadoop.fs.s3a.access.key                              pgm2H2bR7a5kMc5XCYdO
spark.hadoop.fs.s3a.secret.key                              zjd8T0hXFGtfemVQ6AH3yBAPASJNXNbVSx5iddqG
spark.hadoop.fs.s3a.path.style.access                       true
spark.hadoop.fs.s3a.aws.credentials.provider                org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
spark.hadoop.fs.s3a.impl                                    org.apache.hadoop.fs.s3a.S3AFileSystem

#
# spark.kerberos.principal                                    zeppelin@SANDBOX.NET
# spark.kerberos.keytab                                       /apps/security/keytabs/users/zeppelin.keytab

#
spark.driver.extraJavaOptions                               '-Divy.home=/apps/.ivy2 -Djava.security.krb5.conf=/etc/krb5.conf -DAWS_ACCESS_KEY_ID=pgm2H2bR7a5kMc5XCYdO -DAWS_SECRET_ACCESS_KEY=zjd8T0hXFGtfemVQ6AH3yBAPASJNXNbVSx5iddqG'
spark.executor.extraJavaOptions                             '-Divy.home=/apps/.ivy2 -Djava.security.krb5.conf=/etc/krb5.conf -DAWS_ACCESS_KEY_ID=pgm2H2bR7a5kMc5XCYdO -DAWS_SECRET_ACCESS_KEY=zjd8T0hXFGtfemVQ6AH3yBAPASJNXNbVSx5iddqG'
